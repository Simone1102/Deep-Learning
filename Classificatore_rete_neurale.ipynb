{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkLG+uLMJ1tr9LF5mOD1fn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Simone1102/Deep-Learning/blob/main/Classificatore_rete_neurale.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "prM8cZIkxTE1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RETI NEURALI DENSE"
      ],
      "metadata": {
        "id": "5SXqTI3KxbCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nel seguente proggetto andremo a creare diversi modelli di reti neurali per la categorizzazione di due differenti dataframe.\n",
        "1. Per la categorizzazione bi-classe di un dataframe sui tumori, nella quale si andrà a predire se un dato tumore (evento) con un certo numero di features, è **benigno** (classe 0) o **maligno** (classe 1);\n",
        "2. Per la categorizzazione di 3 classi sul dataset Iris, nella quale si andrà a predire se un dato fiore (evento) con un certo numero di features, è una **Setosa** (classe 0), **Versicolor** (classe 1) o **Virginica** (classe 2)"
      ],
      "metadata": {
        "id": "tO410oMpxfOK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CATEGORIZZAZIONE DEI TUMORI TRAMITE RETE NEURALE"
      ],
      "metadata": {
        "id": "DBaLlSgsxmRD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Andiamo a importare i dataset e inserire un nome per ogni colonna (che comprenderanno le features e il target). Andando in fine a stampare la tabella di tutti i valori, la tabella descrittiva più la tabella di correlazione delle features."
      ],
      "metadata": {
        "id": "8Yu-JAHwxplz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "breast_cancer = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\",\n",
        "                            names=[\"id\",\"diagnosis\",\"radius_mean\",\"texture_mean\",\"perimeter_mean\",\"area_mean\",\"smoothness_mean\",\"compactness_mean\",\"concavity_mean\",\"concave points_mean\",\"symmetry_mean\",\"fractal_dimension_mean\",\"radius_se\",\"texture_se\",\"perimeter_se\",\"area_se\",\"smoothness_se\",\"compactness_se\",\"concavity_se\",\"concave points_se\",\"symmetry_se\",\"fractal_dimension_se\",\"radius_worst\",\"texture_worst\",\"perimeter_worst\",\"area_worst\",\"smoothness_worst\",\"compactness_worst\",\"concavity_worst\",\"concave points_worst\",\"symmetry_worst\",\"fractal_dimension_worst\"])\n",
        "\n",
        "display(breast_cancer)\n",
        "display(breast_cancer.describe())\n",
        "display((breast_cancer.drop(['diagnosis','id'],axis=1)).corr())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IXSWSh8fxorL",
        "outputId": "163f6191-618a-4718-f87f-b590ba40651b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0      842302         M        17.99         10.38          122.80     1001.0   \n",
              "1      842517         M        20.57         17.77          132.90     1326.0   \n",
              "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3    84348301         M        11.42         20.38           77.58      386.1   \n",
              "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
              "..        ...       ...          ...           ...             ...        ...   \n",
              "564    926424         M        21.56         22.39          142.00     1479.0   \n",
              "565    926682         M        20.13         28.25          131.20     1261.0   \n",
              "566    926954         M        16.60         28.08          108.30      858.1   \n",
              "567    927241         M        20.60         29.33          140.10     1265.0   \n",
              "568     92751         B         7.76         24.54           47.92      181.0   \n",
              "\n",
              "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0            0.11840           0.27760         0.30010              0.14710   \n",
              "1            0.08474           0.07864         0.08690              0.07017   \n",
              "2            0.10960           0.15990         0.19740              0.12790   \n",
              "3            0.14250           0.28390         0.24140              0.10520   \n",
              "4            0.10030           0.13280         0.19800              0.10430   \n",
              "..               ...               ...             ...                  ...   \n",
              "564          0.11100           0.11590         0.24390              0.13890   \n",
              "565          0.09780           0.10340         0.14400              0.09791   \n",
              "566          0.08455           0.10230         0.09251              0.05302   \n",
              "567          0.11780           0.27700         0.35140              0.15200   \n",
              "568          0.05263           0.04362         0.00000              0.00000   \n",
              "\n",
              "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
              "0    ...        25.380          17.33           184.60      2019.0   \n",
              "1    ...        24.990          23.41           158.80      1956.0   \n",
              "2    ...        23.570          25.53           152.50      1709.0   \n",
              "3    ...        14.910          26.50            98.87       567.7   \n",
              "4    ...        22.540          16.67           152.20      1575.0   \n",
              "..   ...           ...            ...              ...         ...   \n",
              "564  ...        25.450          26.40           166.10      2027.0   \n",
              "565  ...        23.690          38.25           155.00      1731.0   \n",
              "566  ...        18.980          34.12           126.70      1124.0   \n",
              "567  ...        25.740          39.42           184.60      1821.0   \n",
              "568  ...         9.456          30.37            59.16       268.6   \n",
              "\n",
              "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
              "0             0.16220            0.66560           0.7119   \n",
              "1             0.12380            0.18660           0.2416   \n",
              "2             0.14440            0.42450           0.4504   \n",
              "3             0.20980            0.86630           0.6869   \n",
              "4             0.13740            0.20500           0.4000   \n",
              "..                ...                ...              ...   \n",
              "564           0.14100            0.21130           0.4107   \n",
              "565           0.11660            0.19220           0.3215   \n",
              "566           0.11390            0.30940           0.3403   \n",
              "567           0.16500            0.86810           0.9387   \n",
              "568           0.08996            0.06444           0.0000   \n",
              "\n",
              "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
              "0                  0.2654          0.4601                  0.11890  \n",
              "1                  0.1860          0.2750                  0.08902  \n",
              "2                  0.2430          0.3613                  0.08758  \n",
              "3                  0.2575          0.6638                  0.17300  \n",
              "4                  0.1625          0.2364                  0.07678  \n",
              "..                    ...             ...                      ...  \n",
              "564                0.2216          0.2060                  0.07115  \n",
              "565                0.1628          0.2572                  0.06637  \n",
              "566                0.1418          0.2218                  0.07820  \n",
              "567                0.2650          0.4087                  0.12400  \n",
              "568                0.0000          0.2871                  0.07039  \n",
              "\n",
              "[569 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21b9743e-f68b-473c-b55f-36de7f0abca2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>926424</td>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>926682</td>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>926954</td>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>927241</td>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>92751</td>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 32 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21b9743e-f68b-473c-b55f-36de7f0abca2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-21b9743e-f68b-473c-b55f-36de7f0abca2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-21b9743e-f68b-473c-b55f-36de7f0abca2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-39a08677-b81f-405f-9426-4836042e8b04\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-39a08677-b81f-405f-9426-4836042e8b04')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-39a08677-b81f-405f-9426-4836042e8b04 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "breast_cancer"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
              "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
              "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
              "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
              "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
              "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
              "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
              "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
              "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
              "\n",
              "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "count       569.000000        569.000000      569.000000           569.000000   \n",
              "mean          0.096360          0.104341        0.088799             0.048919   \n",
              "std           0.014064          0.052813        0.079720             0.038803   \n",
              "min           0.052630          0.019380        0.000000             0.000000   \n",
              "25%           0.086370          0.064920        0.029560             0.020310   \n",
              "50%           0.095870          0.092630        0.061540             0.033500   \n",
              "75%           0.105300          0.130400        0.130700             0.074000   \n",
              "max           0.163400          0.345400        0.426800             0.201200   \n",
              "\n",
              "       symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
              "count     569.000000  ...    569.000000     569.000000       569.000000   \n",
              "mean        0.181162  ...     16.269190      25.677223       107.261213   \n",
              "std         0.027414  ...      4.833242       6.146258        33.602542   \n",
              "min         0.106000  ...      7.930000      12.020000        50.410000   \n",
              "25%         0.161900  ...     13.010000      21.080000        84.110000   \n",
              "50%         0.179200  ...     14.970000      25.410000        97.660000   \n",
              "75%         0.195700  ...     18.790000      29.720000       125.400000   \n",
              "max         0.304000  ...     36.040000      49.540000       251.200000   \n",
              "\n",
              "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
              "count   569.000000        569.000000         569.000000       569.000000   \n",
              "mean    880.583128          0.132369           0.254265         0.272188   \n",
              "std     569.356993          0.022832           0.157336         0.208624   \n",
              "min     185.200000          0.071170           0.027290         0.000000   \n",
              "25%     515.300000          0.116600           0.147200         0.114500   \n",
              "50%     686.500000          0.131300           0.211900         0.226700   \n",
              "75%    1084.000000          0.146000           0.339100         0.382900   \n",
              "max    4254.000000          0.222600           1.058000         1.252000   \n",
              "\n",
              "       concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
              "count            569.000000      569.000000               569.000000  \n",
              "mean               0.114606        0.290076                 0.083946  \n",
              "std                0.065732        0.061867                 0.018061  \n",
              "min                0.000000        0.156500                 0.055040  \n",
              "25%                0.064930        0.250400                 0.071460  \n",
              "50%                0.099930        0.282200                 0.080040  \n",
              "75%                0.161400        0.317900                 0.092080  \n",
              "max                0.291000        0.663800                 0.207500  \n",
              "\n",
              "[8 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b23aecf2-38f6-4829-9656-cf8575955fbf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.037183e+07</td>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>...</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.250206e+08</td>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>...</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>8.670000e+03</td>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>...</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.692180e+05</td>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>...</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9.060240e+05</td>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>...</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.813129e+06</td>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>...</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.113205e+08</td>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>...</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b23aecf2-38f6-4829-9656-cf8575955fbf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b23aecf2-38f6-4829-9656-cf8575955fbf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b23aecf2-38f6-4829-9656-cf8575955fbf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7ad7c7e0-d048-42f6-b2ec-ede0ebc9dbd7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7ad7c7e0-d048-42f6-b2ec-ede0ebc9dbd7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7ad7c7e0-d048-42f6-b2ec-ede0ebc9dbd7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                         radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "radius_mean                 1.000000      0.323782        0.997855   0.987357   \n",
              "texture_mean                0.323782      1.000000        0.329533   0.321086   \n",
              "perimeter_mean              0.997855      0.329533        1.000000   0.986507   \n",
              "area_mean                   0.987357      0.321086        0.986507   1.000000   \n",
              "smoothness_mean             0.170581     -0.023389        0.207278   0.177028   \n",
              "compactness_mean            0.506124      0.236702        0.556936   0.498502   \n",
              "concavity_mean              0.676764      0.302418        0.716136   0.685983   \n",
              "concave points_mean         0.822529      0.293464        0.850977   0.823269   \n",
              "symmetry_mean               0.147741      0.071401        0.183027   0.151293   \n",
              "fractal_dimension_mean     -0.311631     -0.076437       -0.261477  -0.283110   \n",
              "radius_se                   0.679090      0.275869        0.691765   0.732562   \n",
              "texture_se                 -0.097317      0.386358       -0.086761  -0.066280   \n",
              "perimeter_se                0.674172      0.281673        0.693135   0.726628   \n",
              "area_se                     0.735864      0.259845        0.744983   0.800086   \n",
              "smoothness_se              -0.222600      0.006614       -0.202694  -0.166777   \n",
              "compactness_se              0.206000      0.191975        0.250744   0.212583   \n",
              "concavity_se                0.194204      0.143293        0.228082   0.207660   \n",
              "concave points_se           0.376169      0.163851        0.407217   0.372320   \n",
              "symmetry_se                -0.104321      0.009127       -0.081629  -0.072497   \n",
              "fractal_dimension_se       -0.042641      0.054458       -0.005523  -0.019887   \n",
              "radius_worst                0.969539      0.352573        0.969476   0.962746   \n",
              "texture_worst               0.297008      0.912045        0.303038   0.287489   \n",
              "perimeter_worst             0.965137      0.358040        0.970387   0.959120   \n",
              "area_worst                  0.941082      0.343546        0.941550   0.959213   \n",
              "smoothness_worst            0.119616      0.077503        0.150549   0.123523   \n",
              "compactness_worst           0.413463      0.277830        0.455774   0.390410   \n",
              "concavity_worst             0.526911      0.301025        0.563879   0.512606   \n",
              "concave points_worst        0.744214      0.295316        0.771241   0.722017   \n",
              "symmetry_worst              0.163953      0.105008        0.189115   0.143570   \n",
              "fractal_dimension_worst     0.007066      0.119205        0.051019   0.003738   \n",
              "\n",
              "                         smoothness_mean  compactness_mean  concavity_mean  \\\n",
              "radius_mean                     0.170581          0.506124        0.676764   \n",
              "texture_mean                   -0.023389          0.236702        0.302418   \n",
              "perimeter_mean                  0.207278          0.556936        0.716136   \n",
              "area_mean                       0.177028          0.498502        0.685983   \n",
              "smoothness_mean                 1.000000          0.659123        0.521984   \n",
              "compactness_mean                0.659123          1.000000        0.883121   \n",
              "concavity_mean                  0.521984          0.883121        1.000000   \n",
              "concave points_mean             0.553695          0.831135        0.921391   \n",
              "symmetry_mean                   0.557775          0.602641        0.500667   \n",
              "fractal_dimension_mean          0.584792          0.565369        0.336783   \n",
              "radius_se                       0.301467          0.497473        0.631925   \n",
              "texture_se                      0.068406          0.046205        0.076218   \n",
              "perimeter_se                    0.296092          0.548905        0.660391   \n",
              "area_se                         0.246552          0.455653        0.617427   \n",
              "smoothness_se                   0.332375          0.135299        0.098564   \n",
              "compactness_se                  0.318943          0.738722        0.670279   \n",
              "concavity_se                    0.248396          0.570517        0.691270   \n",
              "concave points_se               0.380676          0.642262        0.683260   \n",
              "symmetry_se                     0.200774          0.229977        0.178009   \n",
              "fractal_dimension_se            0.283607          0.507318        0.449301   \n",
              "radius_worst                    0.213120          0.535315        0.688236   \n",
              "texture_worst                   0.036072          0.248133        0.299879   \n",
              "perimeter_worst                 0.238853          0.590210        0.729565   \n",
              "area_worst                      0.206718          0.509604        0.675987   \n",
              "smoothness_worst                0.805324          0.565541        0.448822   \n",
              "compactness_worst               0.472468          0.865809        0.754968   \n",
              "concavity_worst                 0.434926          0.816275        0.884103   \n",
              "concave points_worst            0.503053          0.815573        0.861323   \n",
              "symmetry_worst                  0.394309          0.510223        0.409464   \n",
              "fractal_dimension_worst         0.499316          0.687382        0.514930   \n",
              "\n",
              "                         concave points_mean  symmetry_mean  \\\n",
              "radius_mean                         0.822529       0.147741   \n",
              "texture_mean                        0.293464       0.071401   \n",
              "perimeter_mean                      0.850977       0.183027   \n",
              "area_mean                           0.823269       0.151293   \n",
              "smoothness_mean                     0.553695       0.557775   \n",
              "compactness_mean                    0.831135       0.602641   \n",
              "concavity_mean                      0.921391       0.500667   \n",
              "concave points_mean                 1.000000       0.462497   \n",
              "symmetry_mean                       0.462497       1.000000   \n",
              "fractal_dimension_mean              0.166917       0.479921   \n",
              "radius_se                           0.698050       0.303379   \n",
              "texture_se                          0.021480       0.128053   \n",
              "perimeter_se                        0.710650       0.313893   \n",
              "area_se                             0.690299       0.223970   \n",
              "smoothness_se                       0.027653       0.187321   \n",
              "compactness_se                      0.490424       0.421659   \n",
              "concavity_se                        0.439167       0.342627   \n",
              "concave points_se                   0.615634       0.393298   \n",
              "symmetry_se                         0.095351       0.449137   \n",
              "fractal_dimension_se                0.257584       0.331786   \n",
              "radius_worst                        0.830318       0.185728   \n",
              "texture_worst                       0.292752       0.090651   \n",
              "perimeter_worst                     0.855923       0.219169   \n",
              "area_worst                          0.809630       0.177193   \n",
              "smoothness_worst                    0.452753       0.426675   \n",
              "compactness_worst                   0.667454       0.473200   \n",
              "concavity_worst                     0.752399       0.433721   \n",
              "concave points_worst                0.910155       0.430297   \n",
              "symmetry_worst                      0.375744       0.699826   \n",
              "fractal_dimension_worst             0.368661       0.438413   \n",
              "\n",
              "                         fractal_dimension_mean  ...  radius_worst  \\\n",
              "radius_mean                           -0.311631  ...      0.969539   \n",
              "texture_mean                          -0.076437  ...      0.352573   \n",
              "perimeter_mean                        -0.261477  ...      0.969476   \n",
              "area_mean                             -0.283110  ...      0.962746   \n",
              "smoothness_mean                        0.584792  ...      0.213120   \n",
              "compactness_mean                       0.565369  ...      0.535315   \n",
              "concavity_mean                         0.336783  ...      0.688236   \n",
              "concave points_mean                    0.166917  ...      0.830318   \n",
              "symmetry_mean                          0.479921  ...      0.185728   \n",
              "fractal_dimension_mean                 1.000000  ...     -0.253691   \n",
              "radius_se                              0.000111  ...      0.715065   \n",
              "texture_se                             0.164174  ...     -0.111690   \n",
              "perimeter_se                           0.039830  ...      0.697201   \n",
              "area_se                               -0.090170  ...      0.757373   \n",
              "smoothness_se                          0.401964  ...     -0.230691   \n",
              "compactness_se                         0.559837  ...      0.204607   \n",
              "concavity_se                           0.446630  ...      0.186904   \n",
              "concave points_se                      0.341198  ...      0.358127   \n",
              "symmetry_se                            0.345007  ...     -0.128121   \n",
              "fractal_dimension_se                   0.688132  ...     -0.037488   \n",
              "radius_worst                          -0.253691  ...      1.000000   \n",
              "texture_worst                         -0.051269  ...      0.359921   \n",
              "perimeter_worst                       -0.205151  ...      0.993708   \n",
              "area_worst                            -0.231854  ...      0.984015   \n",
              "smoothness_worst                       0.504942  ...      0.216574   \n",
              "compactness_worst                      0.458798  ...      0.475820   \n",
              "concavity_worst                        0.346234  ...      0.573975   \n",
              "concave points_worst                   0.175325  ...      0.787424   \n",
              "symmetry_worst                         0.334019  ...      0.243529   \n",
              "fractal_dimension_worst                0.767297  ...      0.093492   \n",
              "\n",
              "                         texture_worst  perimeter_worst  area_worst  \\\n",
              "radius_mean                   0.297008         0.965137    0.941082   \n",
              "texture_mean                  0.912045         0.358040    0.343546   \n",
              "perimeter_mean                0.303038         0.970387    0.941550   \n",
              "area_mean                     0.287489         0.959120    0.959213   \n",
              "smoothness_mean               0.036072         0.238853    0.206718   \n",
              "compactness_mean              0.248133         0.590210    0.509604   \n",
              "concavity_mean                0.299879         0.729565    0.675987   \n",
              "concave points_mean           0.292752         0.855923    0.809630   \n",
              "symmetry_mean                 0.090651         0.219169    0.177193   \n",
              "fractal_dimension_mean       -0.051269        -0.205151   -0.231854   \n",
              "radius_se                     0.194799         0.719684    0.751548   \n",
              "texture_se                    0.409003        -0.102242   -0.083195   \n",
              "perimeter_se                  0.200371         0.721031    0.730713   \n",
              "area_se                       0.196497         0.761213    0.811408   \n",
              "smoothness_se                -0.074743        -0.217304   -0.182195   \n",
              "compactness_se                0.143003         0.260516    0.199371   \n",
              "concavity_se                  0.100241         0.226680    0.188353   \n",
              "concave points_se             0.086741         0.394999    0.342271   \n",
              "symmetry_se                  -0.077473        -0.103753   -0.110343   \n",
              "fractal_dimension_se         -0.003195        -0.001000   -0.022736   \n",
              "radius_worst                  0.359921         0.993708    0.984015   \n",
              "texture_worst                 1.000000         0.365098    0.345842   \n",
              "perimeter_worst               0.365098         1.000000    0.977578   \n",
              "area_worst                    0.345842         0.977578    1.000000   \n",
              "smoothness_worst              0.225429         0.236775    0.209145   \n",
              "compactness_worst             0.360832         0.529408    0.438296   \n",
              "concavity_worst               0.368366         0.618344    0.543331   \n",
              "concave points_worst          0.359755         0.816322    0.747419   \n",
              "symmetry_worst                0.233027         0.269493    0.209146   \n",
              "fractal_dimension_worst       0.219122         0.138957    0.079647   \n",
              "\n",
              "                         smoothness_worst  compactness_worst  concavity_worst  \\\n",
              "radius_mean                      0.119616           0.413463         0.526911   \n",
              "texture_mean                     0.077503           0.277830         0.301025   \n",
              "perimeter_mean                   0.150549           0.455774         0.563879   \n",
              "area_mean                        0.123523           0.390410         0.512606   \n",
              "smoothness_mean                  0.805324           0.472468         0.434926   \n",
              "compactness_mean                 0.565541           0.865809         0.816275   \n",
              "concavity_mean                   0.448822           0.754968         0.884103   \n",
              "concave points_mean              0.452753           0.667454         0.752399   \n",
              "symmetry_mean                    0.426675           0.473200         0.433721   \n",
              "fractal_dimension_mean           0.504942           0.458798         0.346234   \n",
              "radius_se                        0.141919           0.287103         0.380585   \n",
              "texture_se                      -0.073658          -0.092439        -0.068956   \n",
              "perimeter_se                     0.130054           0.341919         0.418899   \n",
              "area_se                          0.125389           0.283257         0.385100   \n",
              "smoothness_se                    0.314457          -0.055558        -0.058298   \n",
              "compactness_se                   0.227394           0.678780         0.639147   \n",
              "concavity_se                     0.168481           0.484858         0.662564   \n",
              "concave points_se                0.215351           0.452888         0.549592   \n",
              "symmetry_se                     -0.012662           0.060255         0.037119   \n",
              "fractal_dimension_se             0.170568           0.390159         0.379975   \n",
              "radius_worst                     0.216574           0.475820         0.573975   \n",
              "texture_worst                    0.225429           0.360832         0.368366   \n",
              "perimeter_worst                  0.236775           0.529408         0.618344   \n",
              "area_worst                       0.209145           0.438296         0.543331   \n",
              "smoothness_worst                 1.000000           0.568187         0.518523   \n",
              "compactness_worst                0.568187           1.000000         0.892261   \n",
              "concavity_worst                  0.518523           0.892261         1.000000   \n",
              "concave points_worst             0.547691           0.801080         0.855434   \n",
              "symmetry_worst                   0.493838           0.614441         0.532520   \n",
              "fractal_dimension_worst          0.617624           0.810455         0.686511   \n",
              "\n",
              "                         concave points_worst  symmetry_worst  \\\n",
              "radius_mean                          0.744214        0.163953   \n",
              "texture_mean                         0.295316        0.105008   \n",
              "perimeter_mean                       0.771241        0.189115   \n",
              "area_mean                            0.722017        0.143570   \n",
              "smoothness_mean                      0.503053        0.394309   \n",
              "compactness_mean                     0.815573        0.510223   \n",
              "concavity_mean                       0.861323        0.409464   \n",
              "concave points_mean                  0.910155        0.375744   \n",
              "symmetry_mean                        0.430297        0.699826   \n",
              "fractal_dimension_mean               0.175325        0.334019   \n",
              "radius_se                            0.531062        0.094543   \n",
              "texture_se                          -0.119638       -0.128215   \n",
              "perimeter_se                         0.554897        0.109930   \n",
              "area_se                              0.538166        0.074126   \n",
              "smoothness_se                       -0.102007       -0.107342   \n",
              "compactness_se                       0.483208        0.277878   \n",
              "concavity_se                         0.440472        0.197788   \n",
              "concave points_se                    0.602450        0.143116   \n",
              "symmetry_se                         -0.030413        0.389402   \n",
              "fractal_dimension_se                 0.215204        0.111094   \n",
              "radius_worst                         0.787424        0.243529   \n",
              "texture_worst                        0.359755        0.233027   \n",
              "perimeter_worst                      0.816322        0.269493   \n",
              "area_worst                           0.747419        0.209146   \n",
              "smoothness_worst                     0.547691        0.493838   \n",
              "compactness_worst                    0.801080        0.614441   \n",
              "concavity_worst                      0.855434        0.532520   \n",
              "concave points_worst                 1.000000        0.502528   \n",
              "symmetry_worst                       0.502528        1.000000   \n",
              "fractal_dimension_worst              0.511114        0.537848   \n",
              "\n",
              "                         fractal_dimension_worst  \n",
              "radius_mean                             0.007066  \n",
              "texture_mean                            0.119205  \n",
              "perimeter_mean                          0.051019  \n",
              "area_mean                               0.003738  \n",
              "smoothness_mean                         0.499316  \n",
              "compactness_mean                        0.687382  \n",
              "concavity_mean                          0.514930  \n",
              "concave points_mean                     0.368661  \n",
              "symmetry_mean                           0.438413  \n",
              "fractal_dimension_mean                  0.767297  \n",
              "radius_se                               0.049559  \n",
              "texture_se                             -0.045655  \n",
              "perimeter_se                            0.085433  \n",
              "area_se                                 0.017539  \n",
              "smoothness_se                           0.101480  \n",
              "compactness_se                          0.590973  \n",
              "concavity_se                            0.439329  \n",
              "concave points_se                       0.310655  \n",
              "symmetry_se                             0.078079  \n",
              "fractal_dimension_se                    0.591328  \n",
              "radius_worst                            0.093492  \n",
              "texture_worst                           0.219122  \n",
              "perimeter_worst                         0.138957  \n",
              "area_worst                              0.079647  \n",
              "smoothness_worst                        0.617624  \n",
              "compactness_worst                       0.810455  \n",
              "concavity_worst                         0.686511  \n",
              "concave points_worst                    0.511114  \n",
              "symmetry_worst                          0.537848  \n",
              "fractal_dimension_worst                 1.000000  \n",
              "\n",
              "[30 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-345e0f39-f6f4-477c-b836-54df7992bc93\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>radius_mean</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.323782</td>\n",
              "      <td>0.997855</td>\n",
              "      <td>0.987357</td>\n",
              "      <td>0.170581</td>\n",
              "      <td>0.506124</td>\n",
              "      <td>0.676764</td>\n",
              "      <td>0.822529</td>\n",
              "      <td>0.147741</td>\n",
              "      <td>-0.311631</td>\n",
              "      <td>...</td>\n",
              "      <td>0.969539</td>\n",
              "      <td>0.297008</td>\n",
              "      <td>0.965137</td>\n",
              "      <td>0.941082</td>\n",
              "      <td>0.119616</td>\n",
              "      <td>0.413463</td>\n",
              "      <td>0.526911</td>\n",
              "      <td>0.744214</td>\n",
              "      <td>0.163953</td>\n",
              "      <td>0.007066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>texture_mean</th>\n",
              "      <td>0.323782</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.329533</td>\n",
              "      <td>0.321086</td>\n",
              "      <td>-0.023389</td>\n",
              "      <td>0.236702</td>\n",
              "      <td>0.302418</td>\n",
              "      <td>0.293464</td>\n",
              "      <td>0.071401</td>\n",
              "      <td>-0.076437</td>\n",
              "      <td>...</td>\n",
              "      <td>0.352573</td>\n",
              "      <td>0.912045</td>\n",
              "      <td>0.358040</td>\n",
              "      <td>0.343546</td>\n",
              "      <td>0.077503</td>\n",
              "      <td>0.277830</td>\n",
              "      <td>0.301025</td>\n",
              "      <td>0.295316</td>\n",
              "      <td>0.105008</td>\n",
              "      <td>0.119205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perimeter_mean</th>\n",
              "      <td>0.997855</td>\n",
              "      <td>0.329533</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.986507</td>\n",
              "      <td>0.207278</td>\n",
              "      <td>0.556936</td>\n",
              "      <td>0.716136</td>\n",
              "      <td>0.850977</td>\n",
              "      <td>0.183027</td>\n",
              "      <td>-0.261477</td>\n",
              "      <td>...</td>\n",
              "      <td>0.969476</td>\n",
              "      <td>0.303038</td>\n",
              "      <td>0.970387</td>\n",
              "      <td>0.941550</td>\n",
              "      <td>0.150549</td>\n",
              "      <td>0.455774</td>\n",
              "      <td>0.563879</td>\n",
              "      <td>0.771241</td>\n",
              "      <td>0.189115</td>\n",
              "      <td>0.051019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>area_mean</th>\n",
              "      <td>0.987357</td>\n",
              "      <td>0.321086</td>\n",
              "      <td>0.986507</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.177028</td>\n",
              "      <td>0.498502</td>\n",
              "      <td>0.685983</td>\n",
              "      <td>0.823269</td>\n",
              "      <td>0.151293</td>\n",
              "      <td>-0.283110</td>\n",
              "      <td>...</td>\n",
              "      <td>0.962746</td>\n",
              "      <td>0.287489</td>\n",
              "      <td>0.959120</td>\n",
              "      <td>0.959213</td>\n",
              "      <td>0.123523</td>\n",
              "      <td>0.390410</td>\n",
              "      <td>0.512606</td>\n",
              "      <td>0.722017</td>\n",
              "      <td>0.143570</td>\n",
              "      <td>0.003738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoothness_mean</th>\n",
              "      <td>0.170581</td>\n",
              "      <td>-0.023389</td>\n",
              "      <td>0.207278</td>\n",
              "      <td>0.177028</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.659123</td>\n",
              "      <td>0.521984</td>\n",
              "      <td>0.553695</td>\n",
              "      <td>0.557775</td>\n",
              "      <td>0.584792</td>\n",
              "      <td>...</td>\n",
              "      <td>0.213120</td>\n",
              "      <td>0.036072</td>\n",
              "      <td>0.238853</td>\n",
              "      <td>0.206718</td>\n",
              "      <td>0.805324</td>\n",
              "      <td>0.472468</td>\n",
              "      <td>0.434926</td>\n",
              "      <td>0.503053</td>\n",
              "      <td>0.394309</td>\n",
              "      <td>0.499316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compactness_mean</th>\n",
              "      <td>0.506124</td>\n",
              "      <td>0.236702</td>\n",
              "      <td>0.556936</td>\n",
              "      <td>0.498502</td>\n",
              "      <td>0.659123</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.883121</td>\n",
              "      <td>0.831135</td>\n",
              "      <td>0.602641</td>\n",
              "      <td>0.565369</td>\n",
              "      <td>...</td>\n",
              "      <td>0.535315</td>\n",
              "      <td>0.248133</td>\n",
              "      <td>0.590210</td>\n",
              "      <td>0.509604</td>\n",
              "      <td>0.565541</td>\n",
              "      <td>0.865809</td>\n",
              "      <td>0.816275</td>\n",
              "      <td>0.815573</td>\n",
              "      <td>0.510223</td>\n",
              "      <td>0.687382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concavity_mean</th>\n",
              "      <td>0.676764</td>\n",
              "      <td>0.302418</td>\n",
              "      <td>0.716136</td>\n",
              "      <td>0.685983</td>\n",
              "      <td>0.521984</td>\n",
              "      <td>0.883121</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.921391</td>\n",
              "      <td>0.500667</td>\n",
              "      <td>0.336783</td>\n",
              "      <td>...</td>\n",
              "      <td>0.688236</td>\n",
              "      <td>0.299879</td>\n",
              "      <td>0.729565</td>\n",
              "      <td>0.675987</td>\n",
              "      <td>0.448822</td>\n",
              "      <td>0.754968</td>\n",
              "      <td>0.884103</td>\n",
              "      <td>0.861323</td>\n",
              "      <td>0.409464</td>\n",
              "      <td>0.514930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concave points_mean</th>\n",
              "      <td>0.822529</td>\n",
              "      <td>0.293464</td>\n",
              "      <td>0.850977</td>\n",
              "      <td>0.823269</td>\n",
              "      <td>0.553695</td>\n",
              "      <td>0.831135</td>\n",
              "      <td>0.921391</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.462497</td>\n",
              "      <td>0.166917</td>\n",
              "      <td>...</td>\n",
              "      <td>0.830318</td>\n",
              "      <td>0.292752</td>\n",
              "      <td>0.855923</td>\n",
              "      <td>0.809630</td>\n",
              "      <td>0.452753</td>\n",
              "      <td>0.667454</td>\n",
              "      <td>0.752399</td>\n",
              "      <td>0.910155</td>\n",
              "      <td>0.375744</td>\n",
              "      <td>0.368661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>symmetry_mean</th>\n",
              "      <td>0.147741</td>\n",
              "      <td>0.071401</td>\n",
              "      <td>0.183027</td>\n",
              "      <td>0.151293</td>\n",
              "      <td>0.557775</td>\n",
              "      <td>0.602641</td>\n",
              "      <td>0.500667</td>\n",
              "      <td>0.462497</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.479921</td>\n",
              "      <td>...</td>\n",
              "      <td>0.185728</td>\n",
              "      <td>0.090651</td>\n",
              "      <td>0.219169</td>\n",
              "      <td>0.177193</td>\n",
              "      <td>0.426675</td>\n",
              "      <td>0.473200</td>\n",
              "      <td>0.433721</td>\n",
              "      <td>0.430297</td>\n",
              "      <td>0.699826</td>\n",
              "      <td>0.438413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <td>-0.311631</td>\n",
              "      <td>-0.076437</td>\n",
              "      <td>-0.261477</td>\n",
              "      <td>-0.283110</td>\n",
              "      <td>0.584792</td>\n",
              "      <td>0.565369</td>\n",
              "      <td>0.336783</td>\n",
              "      <td>0.166917</td>\n",
              "      <td>0.479921</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.253691</td>\n",
              "      <td>-0.051269</td>\n",
              "      <td>-0.205151</td>\n",
              "      <td>-0.231854</td>\n",
              "      <td>0.504942</td>\n",
              "      <td>0.458798</td>\n",
              "      <td>0.346234</td>\n",
              "      <td>0.175325</td>\n",
              "      <td>0.334019</td>\n",
              "      <td>0.767297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>radius_se</th>\n",
              "      <td>0.679090</td>\n",
              "      <td>0.275869</td>\n",
              "      <td>0.691765</td>\n",
              "      <td>0.732562</td>\n",
              "      <td>0.301467</td>\n",
              "      <td>0.497473</td>\n",
              "      <td>0.631925</td>\n",
              "      <td>0.698050</td>\n",
              "      <td>0.303379</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>...</td>\n",
              "      <td>0.715065</td>\n",
              "      <td>0.194799</td>\n",
              "      <td>0.719684</td>\n",
              "      <td>0.751548</td>\n",
              "      <td>0.141919</td>\n",
              "      <td>0.287103</td>\n",
              "      <td>0.380585</td>\n",
              "      <td>0.531062</td>\n",
              "      <td>0.094543</td>\n",
              "      <td>0.049559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>texture_se</th>\n",
              "      <td>-0.097317</td>\n",
              "      <td>0.386358</td>\n",
              "      <td>-0.086761</td>\n",
              "      <td>-0.066280</td>\n",
              "      <td>0.068406</td>\n",
              "      <td>0.046205</td>\n",
              "      <td>0.076218</td>\n",
              "      <td>0.021480</td>\n",
              "      <td>0.128053</td>\n",
              "      <td>0.164174</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.111690</td>\n",
              "      <td>0.409003</td>\n",
              "      <td>-0.102242</td>\n",
              "      <td>-0.083195</td>\n",
              "      <td>-0.073658</td>\n",
              "      <td>-0.092439</td>\n",
              "      <td>-0.068956</td>\n",
              "      <td>-0.119638</td>\n",
              "      <td>-0.128215</td>\n",
              "      <td>-0.045655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perimeter_se</th>\n",
              "      <td>0.674172</td>\n",
              "      <td>0.281673</td>\n",
              "      <td>0.693135</td>\n",
              "      <td>0.726628</td>\n",
              "      <td>0.296092</td>\n",
              "      <td>0.548905</td>\n",
              "      <td>0.660391</td>\n",
              "      <td>0.710650</td>\n",
              "      <td>0.313893</td>\n",
              "      <td>0.039830</td>\n",
              "      <td>...</td>\n",
              "      <td>0.697201</td>\n",
              "      <td>0.200371</td>\n",
              "      <td>0.721031</td>\n",
              "      <td>0.730713</td>\n",
              "      <td>0.130054</td>\n",
              "      <td>0.341919</td>\n",
              "      <td>0.418899</td>\n",
              "      <td>0.554897</td>\n",
              "      <td>0.109930</td>\n",
              "      <td>0.085433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>area_se</th>\n",
              "      <td>0.735864</td>\n",
              "      <td>0.259845</td>\n",
              "      <td>0.744983</td>\n",
              "      <td>0.800086</td>\n",
              "      <td>0.246552</td>\n",
              "      <td>0.455653</td>\n",
              "      <td>0.617427</td>\n",
              "      <td>0.690299</td>\n",
              "      <td>0.223970</td>\n",
              "      <td>-0.090170</td>\n",
              "      <td>...</td>\n",
              "      <td>0.757373</td>\n",
              "      <td>0.196497</td>\n",
              "      <td>0.761213</td>\n",
              "      <td>0.811408</td>\n",
              "      <td>0.125389</td>\n",
              "      <td>0.283257</td>\n",
              "      <td>0.385100</td>\n",
              "      <td>0.538166</td>\n",
              "      <td>0.074126</td>\n",
              "      <td>0.017539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoothness_se</th>\n",
              "      <td>-0.222600</td>\n",
              "      <td>0.006614</td>\n",
              "      <td>-0.202694</td>\n",
              "      <td>-0.166777</td>\n",
              "      <td>0.332375</td>\n",
              "      <td>0.135299</td>\n",
              "      <td>0.098564</td>\n",
              "      <td>0.027653</td>\n",
              "      <td>0.187321</td>\n",
              "      <td>0.401964</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.230691</td>\n",
              "      <td>-0.074743</td>\n",
              "      <td>-0.217304</td>\n",
              "      <td>-0.182195</td>\n",
              "      <td>0.314457</td>\n",
              "      <td>-0.055558</td>\n",
              "      <td>-0.058298</td>\n",
              "      <td>-0.102007</td>\n",
              "      <td>-0.107342</td>\n",
              "      <td>0.101480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compactness_se</th>\n",
              "      <td>0.206000</td>\n",
              "      <td>0.191975</td>\n",
              "      <td>0.250744</td>\n",
              "      <td>0.212583</td>\n",
              "      <td>0.318943</td>\n",
              "      <td>0.738722</td>\n",
              "      <td>0.670279</td>\n",
              "      <td>0.490424</td>\n",
              "      <td>0.421659</td>\n",
              "      <td>0.559837</td>\n",
              "      <td>...</td>\n",
              "      <td>0.204607</td>\n",
              "      <td>0.143003</td>\n",
              "      <td>0.260516</td>\n",
              "      <td>0.199371</td>\n",
              "      <td>0.227394</td>\n",
              "      <td>0.678780</td>\n",
              "      <td>0.639147</td>\n",
              "      <td>0.483208</td>\n",
              "      <td>0.277878</td>\n",
              "      <td>0.590973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concavity_se</th>\n",
              "      <td>0.194204</td>\n",
              "      <td>0.143293</td>\n",
              "      <td>0.228082</td>\n",
              "      <td>0.207660</td>\n",
              "      <td>0.248396</td>\n",
              "      <td>0.570517</td>\n",
              "      <td>0.691270</td>\n",
              "      <td>0.439167</td>\n",
              "      <td>0.342627</td>\n",
              "      <td>0.446630</td>\n",
              "      <td>...</td>\n",
              "      <td>0.186904</td>\n",
              "      <td>0.100241</td>\n",
              "      <td>0.226680</td>\n",
              "      <td>0.188353</td>\n",
              "      <td>0.168481</td>\n",
              "      <td>0.484858</td>\n",
              "      <td>0.662564</td>\n",
              "      <td>0.440472</td>\n",
              "      <td>0.197788</td>\n",
              "      <td>0.439329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concave points_se</th>\n",
              "      <td>0.376169</td>\n",
              "      <td>0.163851</td>\n",
              "      <td>0.407217</td>\n",
              "      <td>0.372320</td>\n",
              "      <td>0.380676</td>\n",
              "      <td>0.642262</td>\n",
              "      <td>0.683260</td>\n",
              "      <td>0.615634</td>\n",
              "      <td>0.393298</td>\n",
              "      <td>0.341198</td>\n",
              "      <td>...</td>\n",
              "      <td>0.358127</td>\n",
              "      <td>0.086741</td>\n",
              "      <td>0.394999</td>\n",
              "      <td>0.342271</td>\n",
              "      <td>0.215351</td>\n",
              "      <td>0.452888</td>\n",
              "      <td>0.549592</td>\n",
              "      <td>0.602450</td>\n",
              "      <td>0.143116</td>\n",
              "      <td>0.310655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>symmetry_se</th>\n",
              "      <td>-0.104321</td>\n",
              "      <td>0.009127</td>\n",
              "      <td>-0.081629</td>\n",
              "      <td>-0.072497</td>\n",
              "      <td>0.200774</td>\n",
              "      <td>0.229977</td>\n",
              "      <td>0.178009</td>\n",
              "      <td>0.095351</td>\n",
              "      <td>0.449137</td>\n",
              "      <td>0.345007</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.128121</td>\n",
              "      <td>-0.077473</td>\n",
              "      <td>-0.103753</td>\n",
              "      <td>-0.110343</td>\n",
              "      <td>-0.012662</td>\n",
              "      <td>0.060255</td>\n",
              "      <td>0.037119</td>\n",
              "      <td>-0.030413</td>\n",
              "      <td>0.389402</td>\n",
              "      <td>0.078079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <td>-0.042641</td>\n",
              "      <td>0.054458</td>\n",
              "      <td>-0.005523</td>\n",
              "      <td>-0.019887</td>\n",
              "      <td>0.283607</td>\n",
              "      <td>0.507318</td>\n",
              "      <td>0.449301</td>\n",
              "      <td>0.257584</td>\n",
              "      <td>0.331786</td>\n",
              "      <td>0.688132</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.037488</td>\n",
              "      <td>-0.003195</td>\n",
              "      <td>-0.001000</td>\n",
              "      <td>-0.022736</td>\n",
              "      <td>0.170568</td>\n",
              "      <td>0.390159</td>\n",
              "      <td>0.379975</td>\n",
              "      <td>0.215204</td>\n",
              "      <td>0.111094</td>\n",
              "      <td>0.591328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>radius_worst</th>\n",
              "      <td>0.969539</td>\n",
              "      <td>0.352573</td>\n",
              "      <td>0.969476</td>\n",
              "      <td>0.962746</td>\n",
              "      <td>0.213120</td>\n",
              "      <td>0.535315</td>\n",
              "      <td>0.688236</td>\n",
              "      <td>0.830318</td>\n",
              "      <td>0.185728</td>\n",
              "      <td>-0.253691</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.359921</td>\n",
              "      <td>0.993708</td>\n",
              "      <td>0.984015</td>\n",
              "      <td>0.216574</td>\n",
              "      <td>0.475820</td>\n",
              "      <td>0.573975</td>\n",
              "      <td>0.787424</td>\n",
              "      <td>0.243529</td>\n",
              "      <td>0.093492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>texture_worst</th>\n",
              "      <td>0.297008</td>\n",
              "      <td>0.912045</td>\n",
              "      <td>0.303038</td>\n",
              "      <td>0.287489</td>\n",
              "      <td>0.036072</td>\n",
              "      <td>0.248133</td>\n",
              "      <td>0.299879</td>\n",
              "      <td>0.292752</td>\n",
              "      <td>0.090651</td>\n",
              "      <td>-0.051269</td>\n",
              "      <td>...</td>\n",
              "      <td>0.359921</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.365098</td>\n",
              "      <td>0.345842</td>\n",
              "      <td>0.225429</td>\n",
              "      <td>0.360832</td>\n",
              "      <td>0.368366</td>\n",
              "      <td>0.359755</td>\n",
              "      <td>0.233027</td>\n",
              "      <td>0.219122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perimeter_worst</th>\n",
              "      <td>0.965137</td>\n",
              "      <td>0.358040</td>\n",
              "      <td>0.970387</td>\n",
              "      <td>0.959120</td>\n",
              "      <td>0.238853</td>\n",
              "      <td>0.590210</td>\n",
              "      <td>0.729565</td>\n",
              "      <td>0.855923</td>\n",
              "      <td>0.219169</td>\n",
              "      <td>-0.205151</td>\n",
              "      <td>...</td>\n",
              "      <td>0.993708</td>\n",
              "      <td>0.365098</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.977578</td>\n",
              "      <td>0.236775</td>\n",
              "      <td>0.529408</td>\n",
              "      <td>0.618344</td>\n",
              "      <td>0.816322</td>\n",
              "      <td>0.269493</td>\n",
              "      <td>0.138957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>area_worst</th>\n",
              "      <td>0.941082</td>\n",
              "      <td>0.343546</td>\n",
              "      <td>0.941550</td>\n",
              "      <td>0.959213</td>\n",
              "      <td>0.206718</td>\n",
              "      <td>0.509604</td>\n",
              "      <td>0.675987</td>\n",
              "      <td>0.809630</td>\n",
              "      <td>0.177193</td>\n",
              "      <td>-0.231854</td>\n",
              "      <td>...</td>\n",
              "      <td>0.984015</td>\n",
              "      <td>0.345842</td>\n",
              "      <td>0.977578</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.209145</td>\n",
              "      <td>0.438296</td>\n",
              "      <td>0.543331</td>\n",
              "      <td>0.747419</td>\n",
              "      <td>0.209146</td>\n",
              "      <td>0.079647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoothness_worst</th>\n",
              "      <td>0.119616</td>\n",
              "      <td>0.077503</td>\n",
              "      <td>0.150549</td>\n",
              "      <td>0.123523</td>\n",
              "      <td>0.805324</td>\n",
              "      <td>0.565541</td>\n",
              "      <td>0.448822</td>\n",
              "      <td>0.452753</td>\n",
              "      <td>0.426675</td>\n",
              "      <td>0.504942</td>\n",
              "      <td>...</td>\n",
              "      <td>0.216574</td>\n",
              "      <td>0.225429</td>\n",
              "      <td>0.236775</td>\n",
              "      <td>0.209145</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.568187</td>\n",
              "      <td>0.518523</td>\n",
              "      <td>0.547691</td>\n",
              "      <td>0.493838</td>\n",
              "      <td>0.617624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compactness_worst</th>\n",
              "      <td>0.413463</td>\n",
              "      <td>0.277830</td>\n",
              "      <td>0.455774</td>\n",
              "      <td>0.390410</td>\n",
              "      <td>0.472468</td>\n",
              "      <td>0.865809</td>\n",
              "      <td>0.754968</td>\n",
              "      <td>0.667454</td>\n",
              "      <td>0.473200</td>\n",
              "      <td>0.458798</td>\n",
              "      <td>...</td>\n",
              "      <td>0.475820</td>\n",
              "      <td>0.360832</td>\n",
              "      <td>0.529408</td>\n",
              "      <td>0.438296</td>\n",
              "      <td>0.568187</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.892261</td>\n",
              "      <td>0.801080</td>\n",
              "      <td>0.614441</td>\n",
              "      <td>0.810455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concavity_worst</th>\n",
              "      <td>0.526911</td>\n",
              "      <td>0.301025</td>\n",
              "      <td>0.563879</td>\n",
              "      <td>0.512606</td>\n",
              "      <td>0.434926</td>\n",
              "      <td>0.816275</td>\n",
              "      <td>0.884103</td>\n",
              "      <td>0.752399</td>\n",
              "      <td>0.433721</td>\n",
              "      <td>0.346234</td>\n",
              "      <td>...</td>\n",
              "      <td>0.573975</td>\n",
              "      <td>0.368366</td>\n",
              "      <td>0.618344</td>\n",
              "      <td>0.543331</td>\n",
              "      <td>0.518523</td>\n",
              "      <td>0.892261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.855434</td>\n",
              "      <td>0.532520</td>\n",
              "      <td>0.686511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concave points_worst</th>\n",
              "      <td>0.744214</td>\n",
              "      <td>0.295316</td>\n",
              "      <td>0.771241</td>\n",
              "      <td>0.722017</td>\n",
              "      <td>0.503053</td>\n",
              "      <td>0.815573</td>\n",
              "      <td>0.861323</td>\n",
              "      <td>0.910155</td>\n",
              "      <td>0.430297</td>\n",
              "      <td>0.175325</td>\n",
              "      <td>...</td>\n",
              "      <td>0.787424</td>\n",
              "      <td>0.359755</td>\n",
              "      <td>0.816322</td>\n",
              "      <td>0.747419</td>\n",
              "      <td>0.547691</td>\n",
              "      <td>0.801080</td>\n",
              "      <td>0.855434</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.502528</td>\n",
              "      <td>0.511114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>symmetry_worst</th>\n",
              "      <td>0.163953</td>\n",
              "      <td>0.105008</td>\n",
              "      <td>0.189115</td>\n",
              "      <td>0.143570</td>\n",
              "      <td>0.394309</td>\n",
              "      <td>0.510223</td>\n",
              "      <td>0.409464</td>\n",
              "      <td>0.375744</td>\n",
              "      <td>0.699826</td>\n",
              "      <td>0.334019</td>\n",
              "      <td>...</td>\n",
              "      <td>0.243529</td>\n",
              "      <td>0.233027</td>\n",
              "      <td>0.269493</td>\n",
              "      <td>0.209146</td>\n",
              "      <td>0.493838</td>\n",
              "      <td>0.614441</td>\n",
              "      <td>0.532520</td>\n",
              "      <td>0.502528</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.537848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <td>0.007066</td>\n",
              "      <td>0.119205</td>\n",
              "      <td>0.051019</td>\n",
              "      <td>0.003738</td>\n",
              "      <td>0.499316</td>\n",
              "      <td>0.687382</td>\n",
              "      <td>0.514930</td>\n",
              "      <td>0.368661</td>\n",
              "      <td>0.438413</td>\n",
              "      <td>0.767297</td>\n",
              "      <td>...</td>\n",
              "      <td>0.093492</td>\n",
              "      <td>0.219122</td>\n",
              "      <td>0.138957</td>\n",
              "      <td>0.079647</td>\n",
              "      <td>0.617624</td>\n",
              "      <td>0.810455</td>\n",
              "      <td>0.686511</td>\n",
              "      <td>0.511114</td>\n",
              "      <td>0.537848</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30 rows × 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-345e0f39-f6f4-477c-b836-54df7992bc93')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-345e0f39-f6f4-477c-b836-54df7992bc93 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-345e0f39-f6f4-477c-b836-54df7992bc93');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ee5b8a2a-f449-4aa1-ae3e-babf75da90aa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ee5b8a2a-f449-4aa1-ae3e-babf75da90aa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ee5b8a2a-f449-4aa1-ae3e-babf75da90aa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Andiamo adesso a divudere i dati nelle features e nei target, dopo di che, dato che il target è espresso in numeri anzi che lettere, andiamo ad utilizzare la funzione LabelEncoder per convertire le B e M in 0 e 1 (target), inoltre andiamo anche a standardizzare i vaalori delle features tramite la funzione StandarScaler"
      ],
      "metadata": {
        "id": "zQ5WBDfex2Rl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = breast_cancer.drop(['diagnosis','id'],axis=1).values\n",
        "Y = breast_cancer['diagnosis'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.3, random_state=0)\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)\n",
        "\n",
        "ss = StandardScaler()\n",
        "X_train = ss.fit_transform(X_train)\n",
        "X_test = ss.transform(X_test)"
      ],
      "metadata": {
        "id": "2YSuPts4xvGH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rete neurale densa normale.\n",
        "Importiamo il primo modello di rete neurale densa non profonda, quindi il seguente modello conterrà solo:\n",
        "* 30 **nodi di input**, cioè pari al numero di features del dataframe, con funzione di attivazione **relu**;\n",
        "* 12 **nodi intermedi (nascosti)**, con funzione di attivazione **relu**;\n",
        "* 1 **nodo di output** essendo una categorizzazione binaria, con funzione di attivazione **sigmoidale**."
      ],
      "metadata": {
        "id": "MqXk4Vhsx_i-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=30, activation=\"relu\"))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRQOxGkkx7if",
        "outputId": "f308b052-719e-4781-f4f5-76df050c8a95"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12)                372       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 385 (1.50 KB)\n",
            "Trainable params: 385 (1.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alleniamo il modello sui dati di training:"
      ],
      "metadata": {
        "id": "EBZp6m1EyM_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZoeMgQwyGV9",
        "outputId": "4c9f8c5c-6b61-4a20-f670-b560f7534179"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 2s 6ms/step - loss: 0.8759 - accuracy: 0.3568\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.4221\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6458 - accuracy: 0.5126\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.6809\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5234 - accuracy: 0.7940\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.8342\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4452 - accuracy: 0.8769\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.4140 - accuracy: 0.9070\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3868 - accuracy: 0.9196\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3634 - accuracy: 0.9221\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3420 - accuracy: 0.9271\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.3236 - accuracy: 0.9347\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.3071 - accuracy: 0.9397\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2920 - accuracy: 0.9422\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2783 - accuracy: 0.9447\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.2660 - accuracy: 0.9472\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.2549 - accuracy: 0.9548\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.2448 - accuracy: 0.9548\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.2355 - accuracy: 0.9548\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.2270 - accuracy: 0.9548\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2192 - accuracy: 0.9523\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2122 - accuracy: 0.9497\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2057 - accuracy: 0.9523\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1998 - accuracy: 0.9523\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.1942 - accuracy: 0.9548\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1891 - accuracy: 0.9548\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1844 - accuracy: 0.9548\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1800 - accuracy: 0.9548\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1758 - accuracy: 0.9548\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1720 - accuracy: 0.9548\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1684 - accuracy: 0.9523\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1650 - accuracy: 0.9523\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1618 - accuracy: 0.9523\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1589 - accuracy: 0.9523\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1562 - accuracy: 0.9548\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1535 - accuracy: 0.9598\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1508 - accuracy: 0.9623\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1484 - accuracy: 0.9623\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9623\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9648\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1418 - accuracy: 0.9648\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1398 - accuracy: 0.9648\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.1379 - accuracy: 0.9648\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.1361 - accuracy: 0.9648\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.1343 - accuracy: 0.9648\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1325 - accuracy: 0.9648\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1308 - accuracy: 0.9648\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1291 - accuracy: 0.9648\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1276 - accuracy: 0.9648\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1260 - accuracy: 0.9673\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1247 - accuracy: 0.9673\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1232 - accuracy: 0.9673\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1219 - accuracy: 0.9673\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1205 - accuracy: 0.9673\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1193 - accuracy: 0.9673\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1180 - accuracy: 0.9673\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9673\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1157 - accuracy: 0.9673\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1146 - accuracy: 0.9673\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.1135 - accuracy: 0.9673\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1125 - accuracy: 0.9673\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1115 - accuracy: 0.9673\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1105 - accuracy: 0.9673\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1096 - accuracy: 0.9673\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1086 - accuracy: 0.9698\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1077 - accuracy: 0.9698\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1068 - accuracy: 0.9724\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1060 - accuracy: 0.9724\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1052 - accuracy: 0.9724\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1044 - accuracy: 0.9749\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1036 - accuracy: 0.9749\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1028 - accuracy: 0.9749\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1021 - accuracy: 0.9749\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1013 - accuracy: 0.9749\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1006 - accuracy: 0.9749\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1000 - accuracy: 0.9749\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0993 - accuracy: 0.9749\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0986 - accuracy: 0.9749\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0980 - accuracy: 0.9749\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0973 - accuracy: 0.9749\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0967 - accuracy: 0.9749\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0961 - accuracy: 0.9749\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0955 - accuracy: 0.9749\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0949 - accuracy: 0.9749\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0944 - accuracy: 0.9749\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0938 - accuracy: 0.9749\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0933 - accuracy: 0.9749\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0927 - accuracy: 0.9749\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.0922 - accuracy: 0.9749\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0917 - accuracy: 0.9749\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0911 - accuracy: 0.9749\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0906 - accuracy: 0.9749\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0901 - accuracy: 0.9749\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0896 - accuracy: 0.9749\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0892 - accuracy: 0.9749\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0887 - accuracy: 0.9749\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0883 - accuracy: 0.9749\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0878 - accuracy: 0.9749\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.0874 - accuracy: 0.9749\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0870 - accuracy: 0.9749\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cf957081930>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calcoliamo e printiamo la loss e l'accuratezza sui dati di test:"
      ],
      "metadata": {
        "id": "GMWXTdllyTkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(\"Loss sul test set: %.4f\" % loss)\n",
        "print(\"Accuracy sul test set: %.4f\" % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8JZsoYwyJLX",
        "outputId": "c7c8471a-f5ca-483b-8653-e7e370a48258"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 5ms/step - loss: 0.1011 - accuracy: 0.9474\n",
            "Loss sul test set: 0.1011\n",
            "Accuracy sul test set: 0.9474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importiamo e grafichiamo la matrice di confusione per avere un'idea generale più precisa sulle misure di predizione fatte tramite il seguente modello"
      ],
      "metadata": {
        "id": "Ao9hVs9qya2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict(X_test)\n",
        "y_pred_int = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
        "cm = confusion_matrix(y_test, y_pred_int)\n",
        "labels = ['Benigno', 'Maligno']\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Valori predetti')\n",
        "plt.ylabel('Valori reali')\n",
        "plt.title('Matrice di confusione')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "HSccON_lyW0A",
        "outputId": "11c1cf3e-2f4c-4cc1-ee2d-f53f1532090b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il nostro modello ha dunque:\n",
        "* sbagliato a categorizzare 4 tumori maligni come tumori benigni;\n",
        "* sbagliato a categorizzare 5 tumori benigni come tumori maligni;\n",
        "* correttamente categorizzato 103 tumori benigni su 108;\n",
        "* correttamente categorizzato 59 tumori maligni su 63."
      ],
      "metadata": {
        "id": "HKKzxczhyg-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rete neurale densa profonda.\n",
        "Importiamo ora un modello di rete neurale densa profonda, cioè che avra più di uno strato denso nascosto, quindi il seguente modello conterrà:\n",
        "* 30 **nodi di input**, cioè pari al numero di features del dataframe, con funzione di attivazione **relu**;\n",
        "* 12 **nodi intermedi (nascosti)**, con funzione di attivazione **relu**;\n",
        "* 8 **nodi intermedi (nascosti)**, con funzione di attivazione **relu**;\n",
        "* 4 **nodi intermedi (nascosti)**, con funzione di attivazione **relu**;\n",
        "* 1 **nodo di output** essendo una categorizzazione binaria, con funzione di attivazione **sigmoidale**."
      ],
      "metadata": {
        "id": "UFMz3Xg9yteF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Dense(12, input_dim=X_train.shape[1], activation=\"relu\"))\n",
        "model2.add(Dense(8, activation=\"relu\"))\n",
        "model2.add(Dense(4, activation=\"relu\"))\n",
        "model2.add(Dense(1, activation=\"sigmoid\"))\n",
        "model2.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B41LwF_uyddP",
        "outputId": "d32d8a63-c695-408f-e8cf-24eb5f357e9a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 12)                372       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 4)                 36        \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 517 (2.02 KB)\n",
            "Trainable params: 517 (2.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(X_train, y_train, epochs=150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrkcvA6VyySY",
        "outputId": "ad9e1a2b-18ee-45ec-828d-b7171bb748d7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 0.9925\n",
            "Epoch 2/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9925\n",
            "Epoch 3/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9925\n",
            "Epoch 4/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 0.9925\n",
            "Epoch 5/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 0.9925\n",
            "Epoch 6/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 0.9925\n",
            "Epoch 7/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 0.9925\n",
            "Epoch 8/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.9925\n",
            "Epoch 9/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9925\n",
            "Epoch 10/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9925\n",
            "Epoch 11/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.9925\n",
            "Epoch 12/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 0.9925\n",
            "Epoch 13/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 0.9925\n",
            "Epoch 14/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9925\n",
            "Epoch 15/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.9925\n",
            "Epoch 16/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.9925\n",
            "Epoch 17/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.9925\n",
            "Epoch 18/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 0.9925\n",
            "Epoch 19/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 0.9925\n",
            "Epoch 20/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 0.9925\n",
            "Epoch 21/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.9925\n",
            "Epoch 22/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 0.9925\n",
            "Epoch 23/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9925\n",
            "Epoch 24/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9925\n",
            "Epoch 25/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.9925\n",
            "Epoch 26/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.9925\n",
            "Epoch 27/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9925\n",
            "Epoch 28/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9925\n",
            "Epoch 29/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9925\n",
            "Epoch 30/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9925\n",
            "Epoch 31/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9925\n",
            "Epoch 32/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9925\n",
            "Epoch 33/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 0.9925\n",
            "Epoch 34/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.9925\n",
            "Epoch 35/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9925\n",
            "Epoch 36/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 0.9925\n",
            "Epoch 37/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 0.9925\n",
            "Epoch 38/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 0.9925\n",
            "Epoch 39/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 0.9925\n",
            "Epoch 40/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 0.9925\n",
            "Epoch 41/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 0.9925\n",
            "Epoch 42/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.9925\n",
            "Epoch 43/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.9925\n",
            "Epoch 44/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9925\n",
            "Epoch 45/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9925\n",
            "Epoch 46/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 0.9925\n",
            "Epoch 47/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9925\n",
            "Epoch 48/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 0.9925\n",
            "Epoch 49/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 0.9925\n",
            "Epoch 50/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 0.9925\n",
            "Epoch 51/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9925\n",
            "Epoch 52/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.9925\n",
            "Epoch 53/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.9925\n",
            "Epoch 54/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.9925\n",
            "Epoch 55/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9925\n",
            "Epoch 56/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9925\n",
            "Epoch 57/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9925\n",
            "Epoch 58/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9925\n",
            "Epoch 59/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9925\n",
            "Epoch 60/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 0.9925\n",
            "Epoch 61/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9925\n",
            "Epoch 62/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9925\n",
            "Epoch 63/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9925\n",
            "Epoch 64/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9925\n",
            "Epoch 65/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9950\n",
            "Epoch 66/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9950\n",
            "Epoch 67/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9950\n",
            "Epoch 68/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9950\n",
            "Epoch 69/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9950\n",
            "Epoch 70/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9950\n",
            "Epoch 71/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.9950\n",
            "Epoch 72/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9950\n",
            "Epoch 73/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9950\n",
            "Epoch 74/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9950\n",
            "Epoch 75/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9950\n",
            "Epoch 76/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9950\n",
            "Epoch 77/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9950\n",
            "Epoch 78/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9950\n",
            "Epoch 79/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9950\n",
            "Epoch 80/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9950\n",
            "Epoch 81/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9950\n",
            "Epoch 82/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 0.9950\n",
            "Epoch 83/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 0.9950\n",
            "Epoch 84/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.9950\n",
            "Epoch 85/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9950\n",
            "Epoch 86/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9950\n",
            "Epoch 87/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9950\n",
            "Epoch 88/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9950\n",
            "Epoch 89/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9950\n",
            "Epoch 90/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9950\n",
            "Epoch 91/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9950\n",
            "Epoch 92/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9950\n",
            "Epoch 93/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9950\n",
            "Epoch 94/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9950\n",
            "Epoch 95/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9950\n",
            "Epoch 96/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9950\n",
            "Epoch 97/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9950\n",
            "Epoch 98/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9950\n",
            "Epoch 99/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9950\n",
            "Epoch 100/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.9950\n",
            "Epoch 101/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.9950\n",
            "Epoch 102/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9950\n",
            "Epoch 103/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9950\n",
            "Epoch 104/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9950\n",
            "Epoch 105/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9950\n",
            "Epoch 106/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9950\n",
            "Epoch 107/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9950\n",
            "Epoch 108/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9950\n",
            "Epoch 109/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9950\n",
            "Epoch 110/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9950\n",
            "Epoch 111/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9950\n",
            "Epoch 112/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9950\n",
            "Epoch 113/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9950\n",
            "Epoch 114/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9950\n",
            "Epoch 115/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9950\n",
            "Epoch 116/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9950\n",
            "Epoch 117/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9950\n",
            "Epoch 118/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9950\n",
            "Epoch 119/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9950\n",
            "Epoch 120/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9975\n",
            "Epoch 121/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9950\n",
            "Epoch 122/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9950\n",
            "Epoch 123/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9950\n",
            "Epoch 124/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9950\n",
            "Epoch 125/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9975\n",
            "Epoch 126/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9950\n",
            "Epoch 127/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9950\n",
            "Epoch 128/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9950\n",
            "Epoch 129/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9950\n",
            "Epoch 130/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.9975\n",
            "Epoch 131/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9975\n",
            "Epoch 132/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9975\n",
            "Epoch 133/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9975\n",
            "Epoch 134/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9975\n",
            "Epoch 135/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9975\n",
            "Epoch 136/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9975\n",
            "Epoch 137/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9975\n",
            "Epoch 138/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9975\n",
            "Epoch 139/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9975\n",
            "Epoch 140/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9975\n",
            "Epoch 141/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 0.9975\n",
            "Epoch 142/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9975\n",
            "Epoch 143/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9975\n",
            "Epoch 144/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 0.9975\n",
            "Epoch 145/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9975\n",
            "Epoch 146/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9975\n",
            "Epoch 147/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9975\n",
            "Epoch 148/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9975\n",
            "Epoch 149/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9975\n",
            "Epoch 150/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9975\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cf9479d9360>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model2.evaluate(X_test, y_test)\n",
        "print(\"Loss sul test set: %.4f\" % loss)\n",
        "print(\"Accuracy sul test set: %.4f\" % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOY2Nz08y0de",
        "outputId": "21fb4120-0a33-4825-94bf-f72935745d63"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 5ms/step - loss: 0.2127 - accuracy: 0.9532\n",
            "Loss sul test set: 0.2127\n",
            "Accuracy sul test set: 0.9532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model2.predict(X_test)\n",
        "y_pred_int = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
        "cm = confusion_matrix(y_test, y_pred_int)\n",
        "labels = ['Benigno', 'Maligno']\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Valori predetti')\n",
        "plt.ylabel('Valori reali')\n",
        "plt.title('Matrice di confusione')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "iXMjQdx6y39f",
        "outputId": "8d5239fb-558b-4634-a781-7044b994d2bb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il nostro modello ha dunque:\n",
        "* sbagliato a categorizzare 3 tumori maligni come tumori benigni;\n",
        "* sbagliato a categorizzare 5 tumori benigni come tumori maligni;\n",
        "* correttamente categorizzato 103 tumori benigni su 108;\n",
        "* correttamente categorizzato 60 tumori maligni su 63.\n",
        "\n",
        "Solo aggiungendo qualche strato nascosto in più, il nostro modello di rete neurale artificiale è migliorato notevolmente"
      ],
      "metadata": {
        "id": "qpQIPJQFzPe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CATEGORIZZAZIONE DELLA SPECIE DEI FIORI (DATASET IRIS) TRAMITE RETE NEURALE DENSA"
      ],
      "metadata": {
        "id": "LxcwnDkpzrIR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Andiamo direttamente ad importare la rete neurale densa profonda, ma con qualche dettaglio che andrà cambiato, trattandosi di una categorizzazione a tre classi.\n",
        "\n",
        "Importiamo dunque il dataset e dividiamo le features e i target nei set di addestramento e test:"
      ],
      "metadata": {
        "id": "XQgq6frUzwbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=load_iris()\n",
        "X=dataset.data\n",
        "y=dataset.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "metadata": {
        "id": "GtZ3cHQGzInI"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creiamo il nostro modello di rete neurale densa profonda, sta volta per le funzioni di attivazione degli strati nascosti utilizziamo la **LeakyReLU**, questo cambiamento non è dato dal fatto che ci siano 3 classi, andava ugualmente bene anche la funzione **ReLU**. Quindi la nostra rete neurale sarà composta da:\n",
        "* 4 **nodi di input**, cioè il numero di features del nostro dataframe, con funzione di attivazione **LeakyReLU**;\n",
        "* 20 **nodi di intermedi (nascosti)**, con funzione di attivazione **LeakyReLU**;\n",
        "* 16 **nodi di intermedi (nascosti)**, con funzione di attivazione **LeakyReLU**;\n",
        "* 8 **nodi di intermedi (nascosti)**, con funzione di attivazione **LeakyReLU**;\n",
        "* 3 **nodi di output**, con funzione di attivazione **Softmax**.\n",
        "\n",
        "Ciò che è cambiato è che ora il numero di nodi di output è uguale al numero delle classi non trattandosi più di una categorizzazione binaria, la funzione di attivazione dello strato finale è la **softmax**, che restituisce la probabilità normalizzata per ogni classe. Inoltre cambia la funzione di loss e l'ottimizzazione."
      ],
      "metadata": {
        "id": "Nznv_kYjz69l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = Sequential()\n",
        "model3.add(Dense(20, input_dim=X_train.shape[1]))\n",
        "model3.add(LeakyReLU(alpha=0.1))\n",
        "model3.add(Dense(16))\n",
        "model3.add(LeakyReLU(alpha=0.1))\n",
        "model3.add(Dense(8))\n",
        "model3.add(LeakyReLU(alpha=0.1))\n",
        "model3.add(Dense(3, activation=\"softmax\"))\n",
        "model3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9I-AXhD3z7lX",
        "outputId": "44bbb4b6-1928-4803-a6a8-4411a924ef2c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 20)                100       \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 20)                0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 16)                336       \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 16)                0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 599 (2.34 KB)\n",
            "Trainable params: 599 (2.34 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.fit(X_train, y_train, epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCJnacvnz-bG",
        "outputId": "50b3f429-9b42-49ff-a56e-18bd4b65aab0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "4/4 [==============================] - 1s 8ms/step - loss: 2.1942 - accuracy: 0.3304\n",
            "Epoch 2/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.9366 - accuracy: 0.3304\n",
            "Epoch 3/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.7160 - accuracy: 0.3304\n",
            "Epoch 4/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.5277 - accuracy: 0.4375\n",
            "Epoch 5/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.3729 - accuracy: 0.5089\n",
            "Epoch 6/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.2719 - accuracy: 0.3482\n",
            "Epoch 7/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.1849 - accuracy: 0.3482\n",
            "Epoch 8/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.1505 - accuracy: 0.3482\n",
            "Epoch 9/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.1105 - accuracy: 0.4554\n",
            "Epoch 10/200\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0905 - accuracy: 0.5446\n",
            "Epoch 11/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.0712 - accuracy: 0.5536\n",
            "Epoch 12/200\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0544 - accuracy: 0.6339\n",
            "Epoch 13/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0385 - accuracy: 0.6696\n",
            "Epoch 14/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.0220 - accuracy: 0.6696\n",
            "Epoch 15/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.9965 - accuracy: 0.6696\n",
            "Epoch 16/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9558 - accuracy: 0.6696\n",
            "Epoch 17/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9210 - accuracy: 0.6696\n",
            "Epoch 18/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.8755 - accuracy: 0.7321\n",
            "Epoch 19/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.8283 - accuracy: 0.8304\n",
            "Epoch 20/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7816 - accuracy: 0.8929\n",
            "Epoch 21/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7425 - accuracy: 0.7679\n",
            "Epoch 22/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7082 - accuracy: 0.6875\n",
            "Epoch 23/200\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6781 - accuracy: 0.6696\n",
            "Epoch 24/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6554 - accuracy: 0.6696\n",
            "Epoch 25/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6348 - accuracy: 0.6696\n",
            "Epoch 26/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6133 - accuracy: 0.6875\n",
            "Epoch 27/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5903 - accuracy: 0.7679\n",
            "Epoch 28/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5706 - accuracy: 0.8661\n",
            "Epoch 29/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5512 - accuracy: 0.9375\n",
            "Epoch 30/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5363 - accuracy: 0.9643\n",
            "Epoch 31/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5211 - accuracy: 0.9732\n",
            "Epoch 32/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5073 - accuracy: 0.9554\n",
            "Epoch 33/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4936 - accuracy: 0.9554\n",
            "Epoch 34/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4815 - accuracy: 0.9554\n",
            "Epoch 35/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.9732\n",
            "Epoch 36/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4589 - accuracy: 0.9821\n",
            "Epoch 37/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.9732\n",
            "Epoch 38/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4387 - accuracy: 0.9732\n",
            "Epoch 39/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4292 - accuracy: 0.9821\n",
            "Epoch 40/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4202 - accuracy: 0.9821\n",
            "Epoch 41/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.9732\n",
            "Epoch 42/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4036 - accuracy: 0.9732\n",
            "Epoch 43/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3985 - accuracy: 0.9821\n",
            "Epoch 44/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3894 - accuracy: 0.9732\n",
            "Epoch 45/200\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3830 - accuracy: 0.9732\n",
            "Epoch 46/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3753 - accuracy: 0.9732\n",
            "Epoch 47/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.9732\n",
            "Epoch 48/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3618 - accuracy: 0.9732\n",
            "Epoch 49/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3576 - accuracy: 0.9821\n",
            "Epoch 50/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3516 - accuracy: 0.9821\n",
            "Epoch 51/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3440 - accuracy: 0.9821\n",
            "Epoch 52/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3379 - accuracy: 0.9821\n",
            "Epoch 53/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3322 - accuracy: 0.9821\n",
            "Epoch 54/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3281 - accuracy: 0.9821\n",
            "Epoch 55/200\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3209 - accuracy: 0.9821\n",
            "Epoch 56/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3170 - accuracy: 0.9732\n",
            "Epoch 57/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3100 - accuracy: 0.9821\n",
            "Epoch 58/200\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3069 - accuracy: 0.9821\n",
            "Epoch 59/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3018 - accuracy: 0.9732\n",
            "Epoch 60/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2957 - accuracy: 0.9821\n",
            "Epoch 61/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2894 - accuracy: 0.9821\n",
            "Epoch 62/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2860 - accuracy: 0.9821\n",
            "Epoch 63/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2820 - accuracy: 0.9821\n",
            "Epoch 64/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2762 - accuracy: 0.9821\n",
            "Epoch 65/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2723 - accuracy: 0.9821\n",
            "Epoch 66/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2670 - accuracy: 0.9821\n",
            "Epoch 67/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2643 - accuracy: 0.9821\n",
            "Epoch 68/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2603 - accuracy: 0.9732\n",
            "Epoch 69/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2556 - accuracy: 0.9821\n",
            "Epoch 70/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2488 - accuracy: 0.9821\n",
            "Epoch 71/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2481 - accuracy: 0.9732\n",
            "Epoch 72/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2435 - accuracy: 0.9821\n",
            "Epoch 73/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2385 - accuracy: 0.9732\n",
            "Epoch 74/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2329 - accuracy: 0.9821\n",
            "Epoch 75/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2301 - accuracy: 0.9821\n",
            "Epoch 76/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2276 - accuracy: 0.9821\n",
            "Epoch 77/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2233 - accuracy: 0.9821\n",
            "Epoch 78/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2173 - accuracy: 0.9821\n",
            "Epoch 79/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2147 - accuracy: 0.9821\n",
            "Epoch 80/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2116 - accuracy: 0.9732\n",
            "Epoch 81/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2067 - accuracy: 0.9821\n",
            "Epoch 82/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2026 - accuracy: 0.9821\n",
            "Epoch 83/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1986 - accuracy: 0.9821\n",
            "Epoch 84/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1942 - accuracy: 0.9821\n",
            "Epoch 85/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1898 - accuracy: 0.9821\n",
            "Epoch 86/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1864 - accuracy: 0.9821\n",
            "Epoch 87/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1815 - accuracy: 0.9821\n",
            "Epoch 88/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1801 - accuracy: 0.9821\n",
            "Epoch 89/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1752 - accuracy: 0.9911\n",
            "Epoch 90/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1718 - accuracy: 0.9821\n",
            "Epoch 91/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1689 - accuracy: 0.9821\n",
            "Epoch 92/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1637 - accuracy: 0.9821\n",
            "Epoch 93/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1607 - accuracy: 0.9911\n",
            "Epoch 94/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1570 - accuracy: 0.9911\n",
            "Epoch 95/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1544 - accuracy: 0.9821\n",
            "Epoch 96/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1515 - accuracy: 0.9821\n",
            "Epoch 97/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1476 - accuracy: 0.9821\n",
            "Epoch 98/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1461 - accuracy: 0.9821\n",
            "Epoch 99/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1432 - accuracy: 0.9821\n",
            "Epoch 100/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1408 - accuracy: 0.9821\n",
            "Epoch 101/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1388 - accuracy: 0.9732\n",
            "Epoch 102/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1363 - accuracy: 0.9821\n",
            "Epoch 103/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1317 - accuracy: 0.9911\n",
            "Epoch 104/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9821\n",
            "Epoch 105/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1278 - accuracy: 0.9821\n",
            "Epoch 106/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1253 - accuracy: 0.9911\n",
            "Epoch 107/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1236 - accuracy: 0.9821\n",
            "Epoch 108/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1225 - accuracy: 0.9821\n",
            "Epoch 109/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1185 - accuracy: 0.9821\n",
            "Epoch 110/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1194 - accuracy: 0.9821\n",
            "Epoch 111/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1145 - accuracy: 0.9821\n",
            "Epoch 112/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1143 - accuracy: 0.9821\n",
            "Epoch 113/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1132 - accuracy: 0.9821\n",
            "Epoch 114/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1117 - accuracy: 0.9821\n",
            "Epoch 115/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1082 - accuracy: 0.9821\n",
            "Epoch 116/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1055 - accuracy: 0.9821\n",
            "Epoch 117/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1027 - accuracy: 0.9821\n",
            "Epoch 118/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 0.9821\n",
            "Epoch 119/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0924 - accuracy: 0.9911\n",
            "Epoch 120/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0893 - accuracy: 0.9821\n",
            "Epoch 121/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0873 - accuracy: 0.9821\n",
            "Epoch 122/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0834 - accuracy: 0.9821\n",
            "Epoch 123/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0828 - accuracy: 0.9821\n",
            "Epoch 124/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0816 - accuracy: 0.9821\n",
            "Epoch 125/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0805 - accuracy: 0.9911\n",
            "Epoch 126/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0805 - accuracy: 0.9821\n",
            "Epoch 127/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0804 - accuracy: 0.9821\n",
            "Epoch 128/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0802 - accuracy: 0.9821\n",
            "Epoch 129/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9821\n",
            "Epoch 130/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0767 - accuracy: 0.9911\n",
            "Epoch 131/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0767 - accuracy: 0.9821\n",
            "Epoch 132/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0743 - accuracy: 0.9911\n",
            "Epoch 133/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0752 - accuracy: 0.9821\n",
            "Epoch 134/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0741 - accuracy: 0.9821\n",
            "Epoch 135/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0757 - accuracy: 0.9821\n",
            "Epoch 136/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0741 - accuracy: 0.9821\n",
            "Epoch 137/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0731 - accuracy: 0.9821\n",
            "Epoch 138/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0740 - accuracy: 0.9821\n",
            "Epoch 139/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0723 - accuracy: 0.9821\n",
            "Epoch 140/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.9821\n",
            "Epoch 141/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0710 - accuracy: 0.9911\n",
            "Epoch 142/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.9821\n",
            "Epoch 143/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0760 - accuracy: 0.9821\n",
            "Epoch 144/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.9821\n",
            "Epoch 145/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.9821\n",
            "Epoch 146/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.9821\n",
            "Epoch 147/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9821\n",
            "Epoch 148/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0680 - accuracy: 0.9911\n",
            "Epoch 149/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0688 - accuracy: 0.9911\n",
            "Epoch 150/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9911\n",
            "Epoch 151/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0682 - accuracy: 0.9821\n",
            "Epoch 152/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9821\n",
            "Epoch 153/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0657 - accuracy: 0.9821\n",
            "Epoch 154/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0693 - accuracy: 0.9821\n",
            "Epoch 155/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.9911\n",
            "Epoch 156/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.9821\n",
            "Epoch 157/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.9821\n",
            "Epoch 158/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0754 - accuracy: 0.9732\n",
            "Epoch 159/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.9821\n",
            "Epoch 160/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0656 - accuracy: 0.9821\n",
            "Epoch 161/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0636 - accuracy: 0.9821\n",
            "Epoch 162/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.9821\n",
            "Epoch 163/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.9911\n",
            "Epoch 164/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0638 - accuracy: 0.9821\n",
            "Epoch 165/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0639 - accuracy: 0.9821\n",
            "Epoch 166/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.9911\n",
            "Epoch 167/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.9821\n",
            "Epoch 168/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.9911\n",
            "Epoch 169/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.9821\n",
            "Epoch 170/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0630 - accuracy: 0.9911\n",
            "Epoch 171/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.9911\n",
            "Epoch 172/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0636 - accuracy: 0.9821\n",
            "Epoch 173/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0614 - accuracy: 0.9821\n",
            "Epoch 174/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.9911\n",
            "Epoch 175/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0620 - accuracy: 0.9911\n",
            "Epoch 176/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0610 - accuracy: 0.9911\n",
            "Epoch 177/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.9911\n",
            "Epoch 178/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.9911\n",
            "Epoch 179/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9911\n",
            "Epoch 180/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.9911\n",
            "Epoch 181/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0609 - accuracy: 0.9821\n",
            "Epoch 182/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0606 - accuracy: 0.9821\n",
            "Epoch 183/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0611 - accuracy: 0.9911\n",
            "Epoch 184/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 0.9911\n",
            "Epoch 185/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0615 - accuracy: 0.9821\n",
            "Epoch 186/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0583 - accuracy: 0.9821\n",
            "Epoch 187/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.9821\n",
            "Epoch 188/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0630 - accuracy: 0.9821\n",
            "Epoch 189/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0570 - accuracy: 0.9911\n",
            "Epoch 190/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.9821\n",
            "Epoch 191/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.9821\n",
            "Epoch 192/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0558 - accuracy: 0.9911\n",
            "Epoch 193/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.9821\n",
            "Epoch 194/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.9821\n",
            "Epoch 195/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0594 - accuracy: 0.9821\n",
            "Epoch 196/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 0.9821\n",
            "Epoch 197/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0585 - accuracy: 0.9911\n",
            "Epoch 198/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0586 - accuracy: 0.9911\n",
            "Epoch 199/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0616 - accuracy: 0.9821\n",
            "Epoch 200/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0618 - accuracy: 0.9821\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cf93e587400>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model3.evaluate(X_test, y_test)\n",
        "print(\"Loss sul test set: %.4f\" % loss)\n",
        "print(\"Accuracy sul test set: %.4f\" % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go3kUvy80T-A",
        "outputId": "c835e185-e22c-4d88-bee0-31994f33a7e4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0714 - accuracy: 1.0000\n",
            "Loss sul test set: 0.0714\n",
            "Accuracy sul test set: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model3.predict(X_test)\n",
        "y_pred_int = np.argmax(y_pred, axis=1)\n",
        "cm = confusion_matrix(y_test, y_pred_int)\n",
        "labels = ['Setosa', 'Versicolor', 'Virginica']\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Valori predetti')\n",
        "plt.ylabel('Valori reali')\n",
        "plt.title('Matrice di confusione')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "3mX-zmiA0XnX",
        "outputId": "bfca59fa-7add-44cf-ab35-cf31b20f072c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il nostro modello ha dunque:\n",
        "* Correttamente categorizzato tutti i fiori."
      ],
      "metadata": {
        "id": "jXvryl730hWZ"
      }
    }
  ]
}