{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-02T15:37:31.306168Z",
     "start_time": "2024-04-02T15:37:31.298681Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris               \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RETI NEURALI DENSE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6e16e625658e8c0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nel seguente proggetto andremo a creare diversi modelli di reti neurali per la categorizzazione di due differenti dataframe.\n",
    "1. Per la categorizzazione bi-classe di un dataframe sui tumori, nella quale si andrà a predire se un dato tumore (evento) con un certo numero di features, è **benigno** (classe 0) o **maligno** (classe 1);\n",
    "2. Per la categorizzazione di 3 classi sul dataset Iris, nella quale si andrà a predire se un dato fiore (evento) con un certo numero di features, è una **Setosa** (classe 0), **Versicolor** (classe 1) o **Virginica** (classe 2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7da078e19908516f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CATEGORIZZAZIONE DEI TUMORI TRAMITE RETE NEURALE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "930ebbae5b66c205"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Andiamo a importare i dataset e inserire un nome per ogni colonna (che comprenderanno le features e il target). Andando in fine a stampare la tabella di tutti i valori, la tabella descrittiva più la tabella di correlazione delle features."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d74de3274ed22d8"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0      842302         M        17.99         10.38          122.80     1001.0   \n1      842517         M        20.57         17.77          132.90     1326.0   \n2    84300903         M        19.69         21.25          130.00     1203.0   \n3    84348301         M        11.42         20.38           77.58      386.1   \n4    84358402         M        20.29         14.34          135.10     1297.0   \n..        ...       ...          ...           ...             ...        ...   \n564    926424         M        21.56         22.39          142.00     1479.0   \n565    926682         M        20.13         28.25          131.20     1261.0   \n566    926954         M        16.60         28.08          108.30      858.1   \n567    927241         M        20.60         29.33          140.10     1265.0   \n568     92751         B         7.76         24.54           47.92      181.0   \n\n     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n0            0.11840           0.27760         0.30010              0.14710   \n1            0.08474           0.07864         0.08690              0.07017   \n2            0.10960           0.15990         0.19740              0.12790   \n3            0.14250           0.28390         0.24140              0.10520   \n4            0.10030           0.13280         0.19800              0.10430   \n..               ...               ...             ...                  ...   \n564          0.11100           0.11590         0.24390              0.13890   \n565          0.09780           0.10340         0.14400              0.09791   \n566          0.08455           0.10230         0.09251              0.05302   \n567          0.11780           0.27700         0.35140              0.15200   \n568          0.05263           0.04362         0.00000              0.00000   \n\n     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n0    ...        25.380          17.33           184.60      2019.0   \n1    ...        24.990          23.41           158.80      1956.0   \n2    ...        23.570          25.53           152.50      1709.0   \n3    ...        14.910          26.50            98.87       567.7   \n4    ...        22.540          16.67           152.20      1575.0   \n..   ...           ...            ...              ...         ...   \n564  ...        25.450          26.40           166.10      2027.0   \n565  ...        23.690          38.25           155.00      1731.0   \n566  ...        18.980          34.12           126.70      1124.0   \n567  ...        25.740          39.42           184.60      1821.0   \n568  ...         9.456          30.37            59.16       268.6   \n\n     smoothness_worst  compactness_worst  concavity_worst  \\\n0             0.16220            0.66560           0.7119   \n1             0.12380            0.18660           0.2416   \n2             0.14440            0.42450           0.4504   \n3             0.20980            0.86630           0.6869   \n4             0.13740            0.20500           0.4000   \n..                ...                ...              ...   \n564           0.14100            0.21130           0.4107   \n565           0.11660            0.19220           0.3215   \n566           0.11390            0.30940           0.3403   \n567           0.16500            0.86810           0.9387   \n568           0.08996            0.06444           0.0000   \n\n     concave points_worst  symmetry_worst  fractal_dimension_worst  \n0                  0.2654          0.4601                  0.11890  \n1                  0.1860          0.2750                  0.08902  \n2                  0.2430          0.3613                  0.08758  \n3                  0.2575          0.6638                  0.17300  \n4                  0.1625          0.2364                  0.07678  \n..                    ...             ...                      ...  \n564                0.2216          0.2060                  0.07115  \n565                0.1628          0.2572                  0.06637  \n566                0.1418          0.2218                  0.07820  \n567                0.2650          0.4087                  0.12400  \n568                0.0000          0.2871                  0.07039  \n\n[569 rows x 32 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842302</td>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.30010</td>\n      <td>0.14710</td>\n      <td>...</td>\n      <td>25.380</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.16220</td>\n      <td>0.66560</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.08690</td>\n      <td>0.07017</td>\n      <td>...</td>\n      <td>24.990</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.12380</td>\n      <td>0.18660</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.19740</td>\n      <td>0.12790</td>\n      <td>...</td>\n      <td>23.570</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.14440</td>\n      <td>0.42450</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84348301</td>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.24140</td>\n      <td>0.10520</td>\n      <td>...</td>\n      <td>14.910</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.20980</td>\n      <td>0.86630</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84358402</td>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.19800</td>\n      <td>0.10430</td>\n      <td>...</td>\n      <td>22.540</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.13740</td>\n      <td>0.20500</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>564</th>\n      <td>926424</td>\n      <td>M</td>\n      <td>21.56</td>\n      <td>22.39</td>\n      <td>142.00</td>\n      <td>1479.0</td>\n      <td>0.11100</td>\n      <td>0.11590</td>\n      <td>0.24390</td>\n      <td>0.13890</td>\n      <td>...</td>\n      <td>25.450</td>\n      <td>26.40</td>\n      <td>166.10</td>\n      <td>2027.0</td>\n      <td>0.14100</td>\n      <td>0.21130</td>\n      <td>0.4107</td>\n      <td>0.2216</td>\n      <td>0.2060</td>\n      <td>0.07115</td>\n    </tr>\n    <tr>\n      <th>565</th>\n      <td>926682</td>\n      <td>M</td>\n      <td>20.13</td>\n      <td>28.25</td>\n      <td>131.20</td>\n      <td>1261.0</td>\n      <td>0.09780</td>\n      <td>0.10340</td>\n      <td>0.14400</td>\n      <td>0.09791</td>\n      <td>...</td>\n      <td>23.690</td>\n      <td>38.25</td>\n      <td>155.00</td>\n      <td>1731.0</td>\n      <td>0.11660</td>\n      <td>0.19220</td>\n      <td>0.3215</td>\n      <td>0.1628</td>\n      <td>0.2572</td>\n      <td>0.06637</td>\n    </tr>\n    <tr>\n      <th>566</th>\n      <td>926954</td>\n      <td>M</td>\n      <td>16.60</td>\n      <td>28.08</td>\n      <td>108.30</td>\n      <td>858.1</td>\n      <td>0.08455</td>\n      <td>0.10230</td>\n      <td>0.09251</td>\n      <td>0.05302</td>\n      <td>...</td>\n      <td>18.980</td>\n      <td>34.12</td>\n      <td>126.70</td>\n      <td>1124.0</td>\n      <td>0.11390</td>\n      <td>0.30940</td>\n      <td>0.3403</td>\n      <td>0.1418</td>\n      <td>0.2218</td>\n      <td>0.07820</td>\n    </tr>\n    <tr>\n      <th>567</th>\n      <td>927241</td>\n      <td>M</td>\n      <td>20.60</td>\n      <td>29.33</td>\n      <td>140.10</td>\n      <td>1265.0</td>\n      <td>0.11780</td>\n      <td>0.27700</td>\n      <td>0.35140</td>\n      <td>0.15200</td>\n      <td>...</td>\n      <td>25.740</td>\n      <td>39.42</td>\n      <td>184.60</td>\n      <td>1821.0</td>\n      <td>0.16500</td>\n      <td>0.86810</td>\n      <td>0.9387</td>\n      <td>0.2650</td>\n      <td>0.4087</td>\n      <td>0.12400</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>92751</td>\n      <td>B</td>\n      <td>7.76</td>\n      <td>24.54</td>\n      <td>47.92</td>\n      <td>181.0</td>\n      <td>0.05263</td>\n      <td>0.04362</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>9.456</td>\n      <td>30.37</td>\n      <td>59.16</td>\n      <td>268.6</td>\n      <td>0.08996</td>\n      <td>0.06444</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.2871</td>\n      <td>0.07039</td>\n    </tr>\n  </tbody>\n</table>\n<p>569 rows × 32 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\ncount  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \nmean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \nstd    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \nmin    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \nmax    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n\n       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\ncount       569.000000        569.000000      569.000000           569.000000   \nmean          0.096360          0.104341        0.088799             0.048919   \nstd           0.014064          0.052813        0.079720             0.038803   \nmin           0.052630          0.019380        0.000000             0.000000   \n25%           0.086370          0.064920        0.029560             0.020310   \n50%           0.095870          0.092630        0.061540             0.033500   \n75%           0.105300          0.130400        0.130700             0.074000   \nmax           0.163400          0.345400        0.426800             0.201200   \n\n       symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\ncount     569.000000  ...    569.000000     569.000000       569.000000   \nmean        0.181162  ...     16.269190      25.677223       107.261213   \nstd         0.027414  ...      4.833242       6.146258        33.602542   \nmin         0.106000  ...      7.930000      12.020000        50.410000   \n25%         0.161900  ...     13.010000      21.080000        84.110000   \n50%         0.179200  ...     14.970000      25.410000        97.660000   \n75%         0.195700  ...     18.790000      29.720000       125.400000   \nmax         0.304000  ...     36.040000      49.540000       251.200000   \n\n        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\ncount   569.000000        569.000000         569.000000       569.000000   \nmean    880.583128          0.132369           0.254265         0.272188   \nstd     569.356993          0.022832           0.157336         0.208624   \nmin     185.200000          0.071170           0.027290         0.000000   \n25%     515.300000          0.116600           0.147200         0.114500   \n50%     686.500000          0.131300           0.211900         0.226700   \n75%    1084.000000          0.146000           0.339100         0.382900   \nmax    4254.000000          0.222600           1.058000         1.252000   \n\n       concave points_worst  symmetry_worst  fractal_dimension_worst  \ncount            569.000000      569.000000               569.000000  \nmean               0.114606        0.290076                 0.083946  \nstd                0.065732        0.061867                 0.018061  \nmin                0.000000        0.156500                 0.055040  \n25%                0.064930        0.250400                 0.071460  \n50%                0.099930        0.282200                 0.080040  \n75%                0.161400        0.317900                 0.092080  \nmax                0.291000        0.663800                 0.207500  \n\n[8 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5.690000e+02</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>...</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.037183e+07</td>\n      <td>14.127292</td>\n      <td>19.289649</td>\n      <td>91.969033</td>\n      <td>654.889104</td>\n      <td>0.096360</td>\n      <td>0.104341</td>\n      <td>0.088799</td>\n      <td>0.048919</td>\n      <td>0.181162</td>\n      <td>...</td>\n      <td>16.269190</td>\n      <td>25.677223</td>\n      <td>107.261213</td>\n      <td>880.583128</td>\n      <td>0.132369</td>\n      <td>0.254265</td>\n      <td>0.272188</td>\n      <td>0.114606</td>\n      <td>0.290076</td>\n      <td>0.083946</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.250206e+08</td>\n      <td>3.524049</td>\n      <td>4.301036</td>\n      <td>24.298981</td>\n      <td>351.914129</td>\n      <td>0.014064</td>\n      <td>0.052813</td>\n      <td>0.079720</td>\n      <td>0.038803</td>\n      <td>0.027414</td>\n      <td>...</td>\n      <td>4.833242</td>\n      <td>6.146258</td>\n      <td>33.602542</td>\n      <td>569.356993</td>\n      <td>0.022832</td>\n      <td>0.157336</td>\n      <td>0.208624</td>\n      <td>0.065732</td>\n      <td>0.061867</td>\n      <td>0.018061</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>8.670000e+03</td>\n      <td>6.981000</td>\n      <td>9.710000</td>\n      <td>43.790000</td>\n      <td>143.500000</td>\n      <td>0.052630</td>\n      <td>0.019380</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.106000</td>\n      <td>...</td>\n      <td>7.930000</td>\n      <td>12.020000</td>\n      <td>50.410000</td>\n      <td>185.200000</td>\n      <td>0.071170</td>\n      <td>0.027290</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.156500</td>\n      <td>0.055040</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>8.692180e+05</td>\n      <td>11.700000</td>\n      <td>16.170000</td>\n      <td>75.170000</td>\n      <td>420.300000</td>\n      <td>0.086370</td>\n      <td>0.064920</td>\n      <td>0.029560</td>\n      <td>0.020310</td>\n      <td>0.161900</td>\n      <td>...</td>\n      <td>13.010000</td>\n      <td>21.080000</td>\n      <td>84.110000</td>\n      <td>515.300000</td>\n      <td>0.116600</td>\n      <td>0.147200</td>\n      <td>0.114500</td>\n      <td>0.064930</td>\n      <td>0.250400</td>\n      <td>0.071460</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>9.060240e+05</td>\n      <td>13.370000</td>\n      <td>18.840000</td>\n      <td>86.240000</td>\n      <td>551.100000</td>\n      <td>0.095870</td>\n      <td>0.092630</td>\n      <td>0.061540</td>\n      <td>0.033500</td>\n      <td>0.179200</td>\n      <td>...</td>\n      <td>14.970000</td>\n      <td>25.410000</td>\n      <td>97.660000</td>\n      <td>686.500000</td>\n      <td>0.131300</td>\n      <td>0.211900</td>\n      <td>0.226700</td>\n      <td>0.099930</td>\n      <td>0.282200</td>\n      <td>0.080040</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>8.813129e+06</td>\n      <td>15.780000</td>\n      <td>21.800000</td>\n      <td>104.100000</td>\n      <td>782.700000</td>\n      <td>0.105300</td>\n      <td>0.130400</td>\n      <td>0.130700</td>\n      <td>0.074000</td>\n      <td>0.195700</td>\n      <td>...</td>\n      <td>18.790000</td>\n      <td>29.720000</td>\n      <td>125.400000</td>\n      <td>1084.000000</td>\n      <td>0.146000</td>\n      <td>0.339100</td>\n      <td>0.382900</td>\n      <td>0.161400</td>\n      <td>0.317900</td>\n      <td>0.092080</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.113205e+08</td>\n      <td>28.110000</td>\n      <td>39.280000</td>\n      <td>188.500000</td>\n      <td>2501.000000</td>\n      <td>0.163400</td>\n      <td>0.345400</td>\n      <td>0.426800</td>\n      <td>0.201200</td>\n      <td>0.304000</td>\n      <td>...</td>\n      <td>36.040000</td>\n      <td>49.540000</td>\n      <td>251.200000</td>\n      <td>4254.000000</td>\n      <td>0.222600</td>\n      <td>1.058000</td>\n      <td>1.252000</td>\n      <td>0.291000</td>\n      <td>0.663800</td>\n      <td>0.207500</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 31 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                         radius_mean  texture_mean  perimeter_mean  area_mean  \\\nradius_mean                 1.000000      0.323782        0.997855   0.987357   \ntexture_mean                0.323782      1.000000        0.329533   0.321086   \nperimeter_mean              0.997855      0.329533        1.000000   0.986507   \narea_mean                   0.987357      0.321086        0.986507   1.000000   \nsmoothness_mean             0.170581     -0.023389        0.207278   0.177028   \ncompactness_mean            0.506124      0.236702        0.556936   0.498502   \nconcavity_mean              0.676764      0.302418        0.716136   0.685983   \nconcave points_mean         0.822529      0.293464        0.850977   0.823269   \nsymmetry_mean               0.147741      0.071401        0.183027   0.151293   \nfractal_dimension_mean     -0.311631     -0.076437       -0.261477  -0.283110   \nradius_se                   0.679090      0.275869        0.691765   0.732562   \ntexture_se                 -0.097317      0.386358       -0.086761  -0.066280   \nperimeter_se                0.674172      0.281673        0.693135   0.726628   \narea_se                     0.735864      0.259845        0.744983   0.800086   \nsmoothness_se              -0.222600      0.006614       -0.202694  -0.166777   \ncompactness_se              0.206000      0.191975        0.250744   0.212583   \nconcavity_se                0.194204      0.143293        0.228082   0.207660   \nconcave points_se           0.376169      0.163851        0.407217   0.372320   \nsymmetry_se                -0.104321      0.009127       -0.081629  -0.072497   \nfractal_dimension_se       -0.042641      0.054458       -0.005523  -0.019887   \nradius_worst                0.969539      0.352573        0.969476   0.962746   \ntexture_worst               0.297008      0.912045        0.303038   0.287489   \nperimeter_worst             0.965137      0.358040        0.970387   0.959120   \narea_worst                  0.941082      0.343546        0.941550   0.959213   \nsmoothness_worst            0.119616      0.077503        0.150549   0.123523   \ncompactness_worst           0.413463      0.277830        0.455774   0.390410   \nconcavity_worst             0.526911      0.301025        0.563879   0.512606   \nconcave points_worst        0.744214      0.295316        0.771241   0.722017   \nsymmetry_worst              0.163953      0.105008        0.189115   0.143570   \nfractal_dimension_worst     0.007066      0.119205        0.051019   0.003738   \n\n                         smoothness_mean  compactness_mean  concavity_mean  \\\nradius_mean                     0.170581          0.506124        0.676764   \ntexture_mean                   -0.023389          0.236702        0.302418   \nperimeter_mean                  0.207278          0.556936        0.716136   \narea_mean                       0.177028          0.498502        0.685983   \nsmoothness_mean                 1.000000          0.659123        0.521984   \ncompactness_mean                0.659123          1.000000        0.883121   \nconcavity_mean                  0.521984          0.883121        1.000000   \nconcave points_mean             0.553695          0.831135        0.921391   \nsymmetry_mean                   0.557775          0.602641        0.500667   \nfractal_dimension_mean          0.584792          0.565369        0.336783   \nradius_se                       0.301467          0.497473        0.631925   \ntexture_se                      0.068406          0.046205        0.076218   \nperimeter_se                    0.296092          0.548905        0.660391   \narea_se                         0.246552          0.455653        0.617427   \nsmoothness_se                   0.332375          0.135299        0.098564   \ncompactness_se                  0.318943          0.738722        0.670279   \nconcavity_se                    0.248396          0.570517        0.691270   \nconcave points_se               0.380676          0.642262        0.683260   \nsymmetry_se                     0.200774          0.229977        0.178009   \nfractal_dimension_se            0.283607          0.507318        0.449301   \nradius_worst                    0.213120          0.535315        0.688236   \ntexture_worst                   0.036072          0.248133        0.299879   \nperimeter_worst                 0.238853          0.590210        0.729565   \narea_worst                      0.206718          0.509604        0.675987   \nsmoothness_worst                0.805324          0.565541        0.448822   \ncompactness_worst               0.472468          0.865809        0.754968   \nconcavity_worst                 0.434926          0.816275        0.884103   \nconcave points_worst            0.503053          0.815573        0.861323   \nsymmetry_worst                  0.394309          0.510223        0.409464   \nfractal_dimension_worst         0.499316          0.687382        0.514930   \n\n                         concave points_mean  symmetry_mean  \\\nradius_mean                         0.822529       0.147741   \ntexture_mean                        0.293464       0.071401   \nperimeter_mean                      0.850977       0.183027   \narea_mean                           0.823269       0.151293   \nsmoothness_mean                     0.553695       0.557775   \ncompactness_mean                    0.831135       0.602641   \nconcavity_mean                      0.921391       0.500667   \nconcave points_mean                 1.000000       0.462497   \nsymmetry_mean                       0.462497       1.000000   \nfractal_dimension_mean              0.166917       0.479921   \nradius_se                           0.698050       0.303379   \ntexture_se                          0.021480       0.128053   \nperimeter_se                        0.710650       0.313893   \narea_se                             0.690299       0.223970   \nsmoothness_se                       0.027653       0.187321   \ncompactness_se                      0.490424       0.421659   \nconcavity_se                        0.439167       0.342627   \nconcave points_se                   0.615634       0.393298   \nsymmetry_se                         0.095351       0.449137   \nfractal_dimension_se                0.257584       0.331786   \nradius_worst                        0.830318       0.185728   \ntexture_worst                       0.292752       0.090651   \nperimeter_worst                     0.855923       0.219169   \narea_worst                          0.809630       0.177193   \nsmoothness_worst                    0.452753       0.426675   \ncompactness_worst                   0.667454       0.473200   \nconcavity_worst                     0.752399       0.433721   \nconcave points_worst                0.910155       0.430297   \nsymmetry_worst                      0.375744       0.699826   \nfractal_dimension_worst             0.368661       0.438413   \n\n                         fractal_dimension_mean  ...  radius_worst  \\\nradius_mean                           -0.311631  ...      0.969539   \ntexture_mean                          -0.076437  ...      0.352573   \nperimeter_mean                        -0.261477  ...      0.969476   \narea_mean                             -0.283110  ...      0.962746   \nsmoothness_mean                        0.584792  ...      0.213120   \ncompactness_mean                       0.565369  ...      0.535315   \nconcavity_mean                         0.336783  ...      0.688236   \nconcave points_mean                    0.166917  ...      0.830318   \nsymmetry_mean                          0.479921  ...      0.185728   \nfractal_dimension_mean                 1.000000  ...     -0.253691   \nradius_se                              0.000111  ...      0.715065   \ntexture_se                             0.164174  ...     -0.111690   \nperimeter_se                           0.039830  ...      0.697201   \narea_se                               -0.090170  ...      0.757373   \nsmoothness_se                          0.401964  ...     -0.230691   \ncompactness_se                         0.559837  ...      0.204607   \nconcavity_se                           0.446630  ...      0.186904   \nconcave points_se                      0.341198  ...      0.358127   \nsymmetry_se                            0.345007  ...     -0.128121   \nfractal_dimension_se                   0.688132  ...     -0.037488   \nradius_worst                          -0.253691  ...      1.000000   \ntexture_worst                         -0.051269  ...      0.359921   \nperimeter_worst                       -0.205151  ...      0.993708   \narea_worst                            -0.231854  ...      0.984015   \nsmoothness_worst                       0.504942  ...      0.216574   \ncompactness_worst                      0.458798  ...      0.475820   \nconcavity_worst                        0.346234  ...      0.573975   \nconcave points_worst                   0.175325  ...      0.787424   \nsymmetry_worst                         0.334019  ...      0.243529   \nfractal_dimension_worst                0.767297  ...      0.093492   \n\n                         texture_worst  perimeter_worst  area_worst  \\\nradius_mean                   0.297008         0.965137    0.941082   \ntexture_mean                  0.912045         0.358040    0.343546   \nperimeter_mean                0.303038         0.970387    0.941550   \narea_mean                     0.287489         0.959120    0.959213   \nsmoothness_mean               0.036072         0.238853    0.206718   \ncompactness_mean              0.248133         0.590210    0.509604   \nconcavity_mean                0.299879         0.729565    0.675987   \nconcave points_mean           0.292752         0.855923    0.809630   \nsymmetry_mean                 0.090651         0.219169    0.177193   \nfractal_dimension_mean       -0.051269        -0.205151   -0.231854   \nradius_se                     0.194799         0.719684    0.751548   \ntexture_se                    0.409003        -0.102242   -0.083195   \nperimeter_se                  0.200371         0.721031    0.730713   \narea_se                       0.196497         0.761213    0.811408   \nsmoothness_se                -0.074743        -0.217304   -0.182195   \ncompactness_se                0.143003         0.260516    0.199371   \nconcavity_se                  0.100241         0.226680    0.188353   \nconcave points_se             0.086741         0.394999    0.342271   \nsymmetry_se                  -0.077473        -0.103753   -0.110343   \nfractal_dimension_se         -0.003195        -0.001000   -0.022736   \nradius_worst                  0.359921         0.993708    0.984015   \ntexture_worst                 1.000000         0.365098    0.345842   \nperimeter_worst               0.365098         1.000000    0.977578   \narea_worst                    0.345842         0.977578    1.000000   \nsmoothness_worst              0.225429         0.236775    0.209145   \ncompactness_worst             0.360832         0.529408    0.438296   \nconcavity_worst               0.368366         0.618344    0.543331   \nconcave points_worst          0.359755         0.816322    0.747419   \nsymmetry_worst                0.233027         0.269493    0.209146   \nfractal_dimension_worst       0.219122         0.138957    0.079647   \n\n                         smoothness_worst  compactness_worst  concavity_worst  \\\nradius_mean                      0.119616           0.413463         0.526911   \ntexture_mean                     0.077503           0.277830         0.301025   \nperimeter_mean                   0.150549           0.455774         0.563879   \narea_mean                        0.123523           0.390410         0.512606   \nsmoothness_mean                  0.805324           0.472468         0.434926   \ncompactness_mean                 0.565541           0.865809         0.816275   \nconcavity_mean                   0.448822           0.754968         0.884103   \nconcave points_mean              0.452753           0.667454         0.752399   \nsymmetry_mean                    0.426675           0.473200         0.433721   \nfractal_dimension_mean           0.504942           0.458798         0.346234   \nradius_se                        0.141919           0.287103         0.380585   \ntexture_se                      -0.073658          -0.092439        -0.068956   \nperimeter_se                     0.130054           0.341919         0.418899   \narea_se                          0.125389           0.283257         0.385100   \nsmoothness_se                    0.314457          -0.055558        -0.058298   \ncompactness_se                   0.227394           0.678780         0.639147   \nconcavity_se                     0.168481           0.484858         0.662564   \nconcave points_se                0.215351           0.452888         0.549592   \nsymmetry_se                     -0.012662           0.060255         0.037119   \nfractal_dimension_se             0.170568           0.390159         0.379975   \nradius_worst                     0.216574           0.475820         0.573975   \ntexture_worst                    0.225429           0.360832         0.368366   \nperimeter_worst                  0.236775           0.529408         0.618344   \narea_worst                       0.209145           0.438296         0.543331   \nsmoothness_worst                 1.000000           0.568187         0.518523   \ncompactness_worst                0.568187           1.000000         0.892261   \nconcavity_worst                  0.518523           0.892261         1.000000   \nconcave points_worst             0.547691           0.801080         0.855434   \nsymmetry_worst                   0.493838           0.614441         0.532520   \nfractal_dimension_worst          0.617624           0.810455         0.686511   \n\n                         concave points_worst  symmetry_worst  \\\nradius_mean                          0.744214        0.163953   \ntexture_mean                         0.295316        0.105008   \nperimeter_mean                       0.771241        0.189115   \narea_mean                            0.722017        0.143570   \nsmoothness_mean                      0.503053        0.394309   \ncompactness_mean                     0.815573        0.510223   \nconcavity_mean                       0.861323        0.409464   \nconcave points_mean                  0.910155        0.375744   \nsymmetry_mean                        0.430297        0.699826   \nfractal_dimension_mean               0.175325        0.334019   \nradius_se                            0.531062        0.094543   \ntexture_se                          -0.119638       -0.128215   \nperimeter_se                         0.554897        0.109930   \narea_se                              0.538166        0.074126   \nsmoothness_se                       -0.102007       -0.107342   \ncompactness_se                       0.483208        0.277878   \nconcavity_se                         0.440472        0.197788   \nconcave points_se                    0.602450        0.143116   \nsymmetry_se                         -0.030413        0.389402   \nfractal_dimension_se                 0.215204        0.111094   \nradius_worst                         0.787424        0.243529   \ntexture_worst                        0.359755        0.233027   \nperimeter_worst                      0.816322        0.269493   \narea_worst                           0.747419        0.209146   \nsmoothness_worst                     0.547691        0.493838   \ncompactness_worst                    0.801080        0.614441   \nconcavity_worst                      0.855434        0.532520   \nconcave points_worst                 1.000000        0.502528   \nsymmetry_worst                       0.502528        1.000000   \nfractal_dimension_worst              0.511114        0.537848   \n\n                         fractal_dimension_worst  \nradius_mean                             0.007066  \ntexture_mean                            0.119205  \nperimeter_mean                          0.051019  \narea_mean                               0.003738  \nsmoothness_mean                         0.499316  \ncompactness_mean                        0.687382  \nconcavity_mean                          0.514930  \nconcave points_mean                     0.368661  \nsymmetry_mean                           0.438413  \nfractal_dimension_mean                  0.767297  \nradius_se                               0.049559  \ntexture_se                             -0.045655  \nperimeter_se                            0.085433  \narea_se                                 0.017539  \nsmoothness_se                           0.101480  \ncompactness_se                          0.590973  \nconcavity_se                            0.439329  \nconcave points_se                       0.310655  \nsymmetry_se                             0.078079  \nfractal_dimension_se                    0.591328  \nradius_worst                            0.093492  \ntexture_worst                           0.219122  \nperimeter_worst                         0.138957  \narea_worst                              0.079647  \nsmoothness_worst                        0.617624  \ncompactness_worst                       0.810455  \nconcavity_worst                         0.686511  \nconcave points_worst                    0.511114  \nsymmetry_worst                          0.537848  \nfractal_dimension_worst                 1.000000  \n\n[30 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>fractal_dimension_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>radius_mean</th>\n      <td>1.000000</td>\n      <td>0.323782</td>\n      <td>0.997855</td>\n      <td>0.987357</td>\n      <td>0.170581</td>\n      <td>0.506124</td>\n      <td>0.676764</td>\n      <td>0.822529</td>\n      <td>0.147741</td>\n      <td>-0.311631</td>\n      <td>...</td>\n      <td>0.969539</td>\n      <td>0.297008</td>\n      <td>0.965137</td>\n      <td>0.941082</td>\n      <td>0.119616</td>\n      <td>0.413463</td>\n      <td>0.526911</td>\n      <td>0.744214</td>\n      <td>0.163953</td>\n      <td>0.007066</td>\n    </tr>\n    <tr>\n      <th>texture_mean</th>\n      <td>0.323782</td>\n      <td>1.000000</td>\n      <td>0.329533</td>\n      <td>0.321086</td>\n      <td>-0.023389</td>\n      <td>0.236702</td>\n      <td>0.302418</td>\n      <td>0.293464</td>\n      <td>0.071401</td>\n      <td>-0.076437</td>\n      <td>...</td>\n      <td>0.352573</td>\n      <td>0.912045</td>\n      <td>0.358040</td>\n      <td>0.343546</td>\n      <td>0.077503</td>\n      <td>0.277830</td>\n      <td>0.301025</td>\n      <td>0.295316</td>\n      <td>0.105008</td>\n      <td>0.119205</td>\n    </tr>\n    <tr>\n      <th>perimeter_mean</th>\n      <td>0.997855</td>\n      <td>0.329533</td>\n      <td>1.000000</td>\n      <td>0.986507</td>\n      <td>0.207278</td>\n      <td>0.556936</td>\n      <td>0.716136</td>\n      <td>0.850977</td>\n      <td>0.183027</td>\n      <td>-0.261477</td>\n      <td>...</td>\n      <td>0.969476</td>\n      <td>0.303038</td>\n      <td>0.970387</td>\n      <td>0.941550</td>\n      <td>0.150549</td>\n      <td>0.455774</td>\n      <td>0.563879</td>\n      <td>0.771241</td>\n      <td>0.189115</td>\n      <td>0.051019</td>\n    </tr>\n    <tr>\n      <th>area_mean</th>\n      <td>0.987357</td>\n      <td>0.321086</td>\n      <td>0.986507</td>\n      <td>1.000000</td>\n      <td>0.177028</td>\n      <td>0.498502</td>\n      <td>0.685983</td>\n      <td>0.823269</td>\n      <td>0.151293</td>\n      <td>-0.283110</td>\n      <td>...</td>\n      <td>0.962746</td>\n      <td>0.287489</td>\n      <td>0.959120</td>\n      <td>0.959213</td>\n      <td>0.123523</td>\n      <td>0.390410</td>\n      <td>0.512606</td>\n      <td>0.722017</td>\n      <td>0.143570</td>\n      <td>0.003738</td>\n    </tr>\n    <tr>\n      <th>smoothness_mean</th>\n      <td>0.170581</td>\n      <td>-0.023389</td>\n      <td>0.207278</td>\n      <td>0.177028</td>\n      <td>1.000000</td>\n      <td>0.659123</td>\n      <td>0.521984</td>\n      <td>0.553695</td>\n      <td>0.557775</td>\n      <td>0.584792</td>\n      <td>...</td>\n      <td>0.213120</td>\n      <td>0.036072</td>\n      <td>0.238853</td>\n      <td>0.206718</td>\n      <td>0.805324</td>\n      <td>0.472468</td>\n      <td>0.434926</td>\n      <td>0.503053</td>\n      <td>0.394309</td>\n      <td>0.499316</td>\n    </tr>\n    <tr>\n      <th>compactness_mean</th>\n      <td>0.506124</td>\n      <td>0.236702</td>\n      <td>0.556936</td>\n      <td>0.498502</td>\n      <td>0.659123</td>\n      <td>1.000000</td>\n      <td>0.883121</td>\n      <td>0.831135</td>\n      <td>0.602641</td>\n      <td>0.565369</td>\n      <td>...</td>\n      <td>0.535315</td>\n      <td>0.248133</td>\n      <td>0.590210</td>\n      <td>0.509604</td>\n      <td>0.565541</td>\n      <td>0.865809</td>\n      <td>0.816275</td>\n      <td>0.815573</td>\n      <td>0.510223</td>\n      <td>0.687382</td>\n    </tr>\n    <tr>\n      <th>concavity_mean</th>\n      <td>0.676764</td>\n      <td>0.302418</td>\n      <td>0.716136</td>\n      <td>0.685983</td>\n      <td>0.521984</td>\n      <td>0.883121</td>\n      <td>1.000000</td>\n      <td>0.921391</td>\n      <td>0.500667</td>\n      <td>0.336783</td>\n      <td>...</td>\n      <td>0.688236</td>\n      <td>0.299879</td>\n      <td>0.729565</td>\n      <td>0.675987</td>\n      <td>0.448822</td>\n      <td>0.754968</td>\n      <td>0.884103</td>\n      <td>0.861323</td>\n      <td>0.409464</td>\n      <td>0.514930</td>\n    </tr>\n    <tr>\n      <th>concave points_mean</th>\n      <td>0.822529</td>\n      <td>0.293464</td>\n      <td>0.850977</td>\n      <td>0.823269</td>\n      <td>0.553695</td>\n      <td>0.831135</td>\n      <td>0.921391</td>\n      <td>1.000000</td>\n      <td>0.462497</td>\n      <td>0.166917</td>\n      <td>...</td>\n      <td>0.830318</td>\n      <td>0.292752</td>\n      <td>0.855923</td>\n      <td>0.809630</td>\n      <td>0.452753</td>\n      <td>0.667454</td>\n      <td>0.752399</td>\n      <td>0.910155</td>\n      <td>0.375744</td>\n      <td>0.368661</td>\n    </tr>\n    <tr>\n      <th>symmetry_mean</th>\n      <td>0.147741</td>\n      <td>0.071401</td>\n      <td>0.183027</td>\n      <td>0.151293</td>\n      <td>0.557775</td>\n      <td>0.602641</td>\n      <td>0.500667</td>\n      <td>0.462497</td>\n      <td>1.000000</td>\n      <td>0.479921</td>\n      <td>...</td>\n      <td>0.185728</td>\n      <td>0.090651</td>\n      <td>0.219169</td>\n      <td>0.177193</td>\n      <td>0.426675</td>\n      <td>0.473200</td>\n      <td>0.433721</td>\n      <td>0.430297</td>\n      <td>0.699826</td>\n      <td>0.438413</td>\n    </tr>\n    <tr>\n      <th>fractal_dimension_mean</th>\n      <td>-0.311631</td>\n      <td>-0.076437</td>\n      <td>-0.261477</td>\n      <td>-0.283110</td>\n      <td>0.584792</td>\n      <td>0.565369</td>\n      <td>0.336783</td>\n      <td>0.166917</td>\n      <td>0.479921</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>-0.253691</td>\n      <td>-0.051269</td>\n      <td>-0.205151</td>\n      <td>-0.231854</td>\n      <td>0.504942</td>\n      <td>0.458798</td>\n      <td>0.346234</td>\n      <td>0.175325</td>\n      <td>0.334019</td>\n      <td>0.767297</td>\n    </tr>\n    <tr>\n      <th>radius_se</th>\n      <td>0.679090</td>\n      <td>0.275869</td>\n      <td>0.691765</td>\n      <td>0.732562</td>\n      <td>0.301467</td>\n      <td>0.497473</td>\n      <td>0.631925</td>\n      <td>0.698050</td>\n      <td>0.303379</td>\n      <td>0.000111</td>\n      <td>...</td>\n      <td>0.715065</td>\n      <td>0.194799</td>\n      <td>0.719684</td>\n      <td>0.751548</td>\n      <td>0.141919</td>\n      <td>0.287103</td>\n      <td>0.380585</td>\n      <td>0.531062</td>\n      <td>0.094543</td>\n      <td>0.049559</td>\n    </tr>\n    <tr>\n      <th>texture_se</th>\n      <td>-0.097317</td>\n      <td>0.386358</td>\n      <td>-0.086761</td>\n      <td>-0.066280</td>\n      <td>0.068406</td>\n      <td>0.046205</td>\n      <td>0.076218</td>\n      <td>0.021480</td>\n      <td>0.128053</td>\n      <td>0.164174</td>\n      <td>...</td>\n      <td>-0.111690</td>\n      <td>0.409003</td>\n      <td>-0.102242</td>\n      <td>-0.083195</td>\n      <td>-0.073658</td>\n      <td>-0.092439</td>\n      <td>-0.068956</td>\n      <td>-0.119638</td>\n      <td>-0.128215</td>\n      <td>-0.045655</td>\n    </tr>\n    <tr>\n      <th>perimeter_se</th>\n      <td>0.674172</td>\n      <td>0.281673</td>\n      <td>0.693135</td>\n      <td>0.726628</td>\n      <td>0.296092</td>\n      <td>0.548905</td>\n      <td>0.660391</td>\n      <td>0.710650</td>\n      <td>0.313893</td>\n      <td>0.039830</td>\n      <td>...</td>\n      <td>0.697201</td>\n      <td>0.200371</td>\n      <td>0.721031</td>\n      <td>0.730713</td>\n      <td>0.130054</td>\n      <td>0.341919</td>\n      <td>0.418899</td>\n      <td>0.554897</td>\n      <td>0.109930</td>\n      <td>0.085433</td>\n    </tr>\n    <tr>\n      <th>area_se</th>\n      <td>0.735864</td>\n      <td>0.259845</td>\n      <td>0.744983</td>\n      <td>0.800086</td>\n      <td>0.246552</td>\n      <td>0.455653</td>\n      <td>0.617427</td>\n      <td>0.690299</td>\n      <td>0.223970</td>\n      <td>-0.090170</td>\n      <td>...</td>\n      <td>0.757373</td>\n      <td>0.196497</td>\n      <td>0.761213</td>\n      <td>0.811408</td>\n      <td>0.125389</td>\n      <td>0.283257</td>\n      <td>0.385100</td>\n      <td>0.538166</td>\n      <td>0.074126</td>\n      <td>0.017539</td>\n    </tr>\n    <tr>\n      <th>smoothness_se</th>\n      <td>-0.222600</td>\n      <td>0.006614</td>\n      <td>-0.202694</td>\n      <td>-0.166777</td>\n      <td>0.332375</td>\n      <td>0.135299</td>\n      <td>0.098564</td>\n      <td>0.027653</td>\n      <td>0.187321</td>\n      <td>0.401964</td>\n      <td>...</td>\n      <td>-0.230691</td>\n      <td>-0.074743</td>\n      <td>-0.217304</td>\n      <td>-0.182195</td>\n      <td>0.314457</td>\n      <td>-0.055558</td>\n      <td>-0.058298</td>\n      <td>-0.102007</td>\n      <td>-0.107342</td>\n      <td>0.101480</td>\n    </tr>\n    <tr>\n      <th>compactness_se</th>\n      <td>0.206000</td>\n      <td>0.191975</td>\n      <td>0.250744</td>\n      <td>0.212583</td>\n      <td>0.318943</td>\n      <td>0.738722</td>\n      <td>0.670279</td>\n      <td>0.490424</td>\n      <td>0.421659</td>\n      <td>0.559837</td>\n      <td>...</td>\n      <td>0.204607</td>\n      <td>0.143003</td>\n      <td>0.260516</td>\n      <td>0.199371</td>\n      <td>0.227394</td>\n      <td>0.678780</td>\n      <td>0.639147</td>\n      <td>0.483208</td>\n      <td>0.277878</td>\n      <td>0.590973</td>\n    </tr>\n    <tr>\n      <th>concavity_se</th>\n      <td>0.194204</td>\n      <td>0.143293</td>\n      <td>0.228082</td>\n      <td>0.207660</td>\n      <td>0.248396</td>\n      <td>0.570517</td>\n      <td>0.691270</td>\n      <td>0.439167</td>\n      <td>0.342627</td>\n      <td>0.446630</td>\n      <td>...</td>\n      <td>0.186904</td>\n      <td>0.100241</td>\n      <td>0.226680</td>\n      <td>0.188353</td>\n      <td>0.168481</td>\n      <td>0.484858</td>\n      <td>0.662564</td>\n      <td>0.440472</td>\n      <td>0.197788</td>\n      <td>0.439329</td>\n    </tr>\n    <tr>\n      <th>concave points_se</th>\n      <td>0.376169</td>\n      <td>0.163851</td>\n      <td>0.407217</td>\n      <td>0.372320</td>\n      <td>0.380676</td>\n      <td>0.642262</td>\n      <td>0.683260</td>\n      <td>0.615634</td>\n      <td>0.393298</td>\n      <td>0.341198</td>\n      <td>...</td>\n      <td>0.358127</td>\n      <td>0.086741</td>\n      <td>0.394999</td>\n      <td>0.342271</td>\n      <td>0.215351</td>\n      <td>0.452888</td>\n      <td>0.549592</td>\n      <td>0.602450</td>\n      <td>0.143116</td>\n      <td>0.310655</td>\n    </tr>\n    <tr>\n      <th>symmetry_se</th>\n      <td>-0.104321</td>\n      <td>0.009127</td>\n      <td>-0.081629</td>\n      <td>-0.072497</td>\n      <td>0.200774</td>\n      <td>0.229977</td>\n      <td>0.178009</td>\n      <td>0.095351</td>\n      <td>0.449137</td>\n      <td>0.345007</td>\n      <td>...</td>\n      <td>-0.128121</td>\n      <td>-0.077473</td>\n      <td>-0.103753</td>\n      <td>-0.110343</td>\n      <td>-0.012662</td>\n      <td>0.060255</td>\n      <td>0.037119</td>\n      <td>-0.030413</td>\n      <td>0.389402</td>\n      <td>0.078079</td>\n    </tr>\n    <tr>\n      <th>fractal_dimension_se</th>\n      <td>-0.042641</td>\n      <td>0.054458</td>\n      <td>-0.005523</td>\n      <td>-0.019887</td>\n      <td>0.283607</td>\n      <td>0.507318</td>\n      <td>0.449301</td>\n      <td>0.257584</td>\n      <td>0.331786</td>\n      <td>0.688132</td>\n      <td>...</td>\n      <td>-0.037488</td>\n      <td>-0.003195</td>\n      <td>-0.001000</td>\n      <td>-0.022736</td>\n      <td>0.170568</td>\n      <td>0.390159</td>\n      <td>0.379975</td>\n      <td>0.215204</td>\n      <td>0.111094</td>\n      <td>0.591328</td>\n    </tr>\n    <tr>\n      <th>radius_worst</th>\n      <td>0.969539</td>\n      <td>0.352573</td>\n      <td>0.969476</td>\n      <td>0.962746</td>\n      <td>0.213120</td>\n      <td>0.535315</td>\n      <td>0.688236</td>\n      <td>0.830318</td>\n      <td>0.185728</td>\n      <td>-0.253691</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.359921</td>\n      <td>0.993708</td>\n      <td>0.984015</td>\n      <td>0.216574</td>\n      <td>0.475820</td>\n      <td>0.573975</td>\n      <td>0.787424</td>\n      <td>0.243529</td>\n      <td>0.093492</td>\n    </tr>\n    <tr>\n      <th>texture_worst</th>\n      <td>0.297008</td>\n      <td>0.912045</td>\n      <td>0.303038</td>\n      <td>0.287489</td>\n      <td>0.036072</td>\n      <td>0.248133</td>\n      <td>0.299879</td>\n      <td>0.292752</td>\n      <td>0.090651</td>\n      <td>-0.051269</td>\n      <td>...</td>\n      <td>0.359921</td>\n      <td>1.000000</td>\n      <td>0.365098</td>\n      <td>0.345842</td>\n      <td>0.225429</td>\n      <td>0.360832</td>\n      <td>0.368366</td>\n      <td>0.359755</td>\n      <td>0.233027</td>\n      <td>0.219122</td>\n    </tr>\n    <tr>\n      <th>perimeter_worst</th>\n      <td>0.965137</td>\n      <td>0.358040</td>\n      <td>0.970387</td>\n      <td>0.959120</td>\n      <td>0.238853</td>\n      <td>0.590210</td>\n      <td>0.729565</td>\n      <td>0.855923</td>\n      <td>0.219169</td>\n      <td>-0.205151</td>\n      <td>...</td>\n      <td>0.993708</td>\n      <td>0.365098</td>\n      <td>1.000000</td>\n      <td>0.977578</td>\n      <td>0.236775</td>\n      <td>0.529408</td>\n      <td>0.618344</td>\n      <td>0.816322</td>\n      <td>0.269493</td>\n      <td>0.138957</td>\n    </tr>\n    <tr>\n      <th>area_worst</th>\n      <td>0.941082</td>\n      <td>0.343546</td>\n      <td>0.941550</td>\n      <td>0.959213</td>\n      <td>0.206718</td>\n      <td>0.509604</td>\n      <td>0.675987</td>\n      <td>0.809630</td>\n      <td>0.177193</td>\n      <td>-0.231854</td>\n      <td>...</td>\n      <td>0.984015</td>\n      <td>0.345842</td>\n      <td>0.977578</td>\n      <td>1.000000</td>\n      <td>0.209145</td>\n      <td>0.438296</td>\n      <td>0.543331</td>\n      <td>0.747419</td>\n      <td>0.209146</td>\n      <td>0.079647</td>\n    </tr>\n    <tr>\n      <th>smoothness_worst</th>\n      <td>0.119616</td>\n      <td>0.077503</td>\n      <td>0.150549</td>\n      <td>0.123523</td>\n      <td>0.805324</td>\n      <td>0.565541</td>\n      <td>0.448822</td>\n      <td>0.452753</td>\n      <td>0.426675</td>\n      <td>0.504942</td>\n      <td>...</td>\n      <td>0.216574</td>\n      <td>0.225429</td>\n      <td>0.236775</td>\n      <td>0.209145</td>\n      <td>1.000000</td>\n      <td>0.568187</td>\n      <td>0.518523</td>\n      <td>0.547691</td>\n      <td>0.493838</td>\n      <td>0.617624</td>\n    </tr>\n    <tr>\n      <th>compactness_worst</th>\n      <td>0.413463</td>\n      <td>0.277830</td>\n      <td>0.455774</td>\n      <td>0.390410</td>\n      <td>0.472468</td>\n      <td>0.865809</td>\n      <td>0.754968</td>\n      <td>0.667454</td>\n      <td>0.473200</td>\n      <td>0.458798</td>\n      <td>...</td>\n      <td>0.475820</td>\n      <td>0.360832</td>\n      <td>0.529408</td>\n      <td>0.438296</td>\n      <td>0.568187</td>\n      <td>1.000000</td>\n      <td>0.892261</td>\n      <td>0.801080</td>\n      <td>0.614441</td>\n      <td>0.810455</td>\n    </tr>\n    <tr>\n      <th>concavity_worst</th>\n      <td>0.526911</td>\n      <td>0.301025</td>\n      <td>0.563879</td>\n      <td>0.512606</td>\n      <td>0.434926</td>\n      <td>0.816275</td>\n      <td>0.884103</td>\n      <td>0.752399</td>\n      <td>0.433721</td>\n      <td>0.346234</td>\n      <td>...</td>\n      <td>0.573975</td>\n      <td>0.368366</td>\n      <td>0.618344</td>\n      <td>0.543331</td>\n      <td>0.518523</td>\n      <td>0.892261</td>\n      <td>1.000000</td>\n      <td>0.855434</td>\n      <td>0.532520</td>\n      <td>0.686511</td>\n    </tr>\n    <tr>\n      <th>concave points_worst</th>\n      <td>0.744214</td>\n      <td>0.295316</td>\n      <td>0.771241</td>\n      <td>0.722017</td>\n      <td>0.503053</td>\n      <td>0.815573</td>\n      <td>0.861323</td>\n      <td>0.910155</td>\n      <td>0.430297</td>\n      <td>0.175325</td>\n      <td>...</td>\n      <td>0.787424</td>\n      <td>0.359755</td>\n      <td>0.816322</td>\n      <td>0.747419</td>\n      <td>0.547691</td>\n      <td>0.801080</td>\n      <td>0.855434</td>\n      <td>1.000000</td>\n      <td>0.502528</td>\n      <td>0.511114</td>\n    </tr>\n    <tr>\n      <th>symmetry_worst</th>\n      <td>0.163953</td>\n      <td>0.105008</td>\n      <td>0.189115</td>\n      <td>0.143570</td>\n      <td>0.394309</td>\n      <td>0.510223</td>\n      <td>0.409464</td>\n      <td>0.375744</td>\n      <td>0.699826</td>\n      <td>0.334019</td>\n      <td>...</td>\n      <td>0.243529</td>\n      <td>0.233027</td>\n      <td>0.269493</td>\n      <td>0.209146</td>\n      <td>0.493838</td>\n      <td>0.614441</td>\n      <td>0.532520</td>\n      <td>0.502528</td>\n      <td>1.000000</td>\n      <td>0.537848</td>\n    </tr>\n    <tr>\n      <th>fractal_dimension_worst</th>\n      <td>0.007066</td>\n      <td>0.119205</td>\n      <td>0.051019</td>\n      <td>0.003738</td>\n      <td>0.499316</td>\n      <td>0.687382</td>\n      <td>0.514930</td>\n      <td>0.368661</td>\n      <td>0.438413</td>\n      <td>0.767297</td>\n      <td>...</td>\n      <td>0.093492</td>\n      <td>0.219122</td>\n      <td>0.138957</td>\n      <td>0.079647</td>\n      <td>0.617624</td>\n      <td>0.810455</td>\n      <td>0.686511</td>\n      <td>0.511114</td>\n      <td>0.537848</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>30 rows × 30 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "breast_cancer = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\",\n",
    "                            names=[\"id\",\"diagnosis\",\"radius_mean\",\"texture_mean\",\"perimeter_mean\",\"area_mean\",\"smoothness_mean\",\"compactness_mean\",\"concavity_mean\",\"concave points_mean\",\"symmetry_mean\",\"fractal_dimension_mean\",\"radius_se\",\"texture_se\",\"perimeter_se\",\"area_se\",\"smoothness_se\",\"compactness_se\",\"concavity_se\",\"concave points_se\",\"symmetry_se\",\"fractal_dimension_se\",\"radius_worst\",\"texture_worst\",\"perimeter_worst\",\"area_worst\",\"smoothness_worst\",\"compactness_worst\",\"concavity_worst\",\"concave points_worst\",\"symmetry_worst\",\"fractal_dimension_worst\"])\n",
    "\n",
    "display(breast_cancer)\n",
    "display(breast_cancer.describe())\n",
    "display((breast_cancer.drop(['diagnosis','id'],axis=1)).corr())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T16:16:34.768410Z",
     "start_time": "2024-04-02T16:16:33.076464Z"
    }
   },
   "id": "6d248a2ee1d758b7",
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "source": [
    "Andiamo adesso a divudere i dati nelle features e nei target, dopo di che, dato che il target è espresso in numeri anzi che lettere, andiamo ad utilizzare la funzione LabelEncoder per convertire le B e M in 0 e 1 (target), inoltre andiamo anche a standardizzare i vaalori delle features tramite la funzione StandarScaler"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "162a4d09499b9fa2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X = breast_cancer.drop(['diagnosis','id'],axis=1).values\n",
    "Y = breast_cancer['diagnosis'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.3, random_state=0)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T15:52:58.667353Z",
     "start_time": "2024-04-02T15:52:58.654397Z"
    }
   },
   "id": "dd8a1f19c6a8e4c4",
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Rete neurale densa normale.\n",
    "Importiamo il primo modello di rete neurale densa non profonda, quindi il seguente modello conterrà solo:\n",
    "* 30 **nodi di input**, cioè pari al numero di features del dataframe, con funzione di attivazione **relu**;\n",
    "* 12 **nodi intermedi (nascosti)**, con funzione di attivazione **relu**;\n",
    "* 1 **nodo di output** essendo una categorizzazione binaria, con funzione di attivazione **sigmoidale**."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df4679167c9f57a4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"sequential_4\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense_12 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m12\u001B[0m)             │           \u001B[38;5;34m372\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_13 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m13\u001B[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m385\u001B[0m (1.50 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">385</span> (1.50 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m385\u001B[0m (1.50 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">385</span> (1.50 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=30, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T16:00:36.656183Z",
     "start_time": "2024-04-02T16:00:36.585218Z"
    }
   },
   "id": "7109b0b4ac3d2e2",
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alleniamo il modello sui dati di training:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fddf986a47981c19"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 2ms/step - accuracy: 0.5726 - loss: 0.6790\n",
      "Epoch 2/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6919 - loss: 0.6088 \n",
      "Epoch 3/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8023 - loss: 0.5427 \n",
      "Epoch 4/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8309 - loss: 0.4988 \n",
      "Epoch 5/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9026 - loss: 0.4472 \n",
      "Epoch 6/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8911 - loss: 0.4099 \n",
      "Epoch 7/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9327 - loss: 0.3690 \n",
      "Epoch 8/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9240 - loss: 0.3387 \n",
      "Epoch 9/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9288 - loss: 0.3211 \n",
      "Epoch 10/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9490 - loss: 0.2995 \n",
      "Epoch 11/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9383 - loss: 0.2806 \n",
      "Epoch 12/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9324 - loss: 0.2879 \n",
      "Epoch 13/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9432 - loss: 0.2508 \n",
      "Epoch 14/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9387 - loss: 0.2541 \n",
      "Epoch 15/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9401 - loss: 0.2377 \n",
      "Epoch 16/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9454 - loss: 0.2320 \n",
      "Epoch 17/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9332 - loss: 0.2452 \n",
      "Epoch 18/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9383 - loss: 0.2164 \n",
      "Epoch 19/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9522 - loss: 0.2033 \n",
      "Epoch 20/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9525 - loss: 0.1857 \n",
      "Epoch 21/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9367 - loss: 0.2083 \n",
      "Epoch 22/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9389 - loss: 0.1808 \n",
      "Epoch 23/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9540 - loss: 0.1855 \n",
      "Epoch 24/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9602 - loss: 0.1688 \n",
      "Epoch 25/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9421 - loss: 0.1848 \n",
      "Epoch 26/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9554 - loss: 0.1576 \n",
      "Epoch 27/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9649 - loss: 0.1440 \n",
      "Epoch 28/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9514 - loss: 0.1586 \n",
      "Epoch 29/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9459 - loss: 0.1687 \n",
      "Epoch 30/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9627 - loss: 0.1520 \n",
      "Epoch 31/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9499 - loss: 0.1525 \n",
      "Epoch 32/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9554 - loss: 0.1387 \n",
      "Epoch 33/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9670 - loss: 0.1291 \n",
      "Epoch 34/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9481 - loss: 0.1421 \n",
      "Epoch 35/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9536 - loss: 0.1387 \n",
      "Epoch 36/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9655 - loss: 0.1327 \n",
      "Epoch 37/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9561 - loss: 0.1335 \n",
      "Epoch 38/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9461 - loss: 0.1485 \n",
      "Epoch 39/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9499 - loss: 0.1410 \n",
      "Epoch 40/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9566 - loss: 0.1315 \n",
      "Epoch 41/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9507 - loss: 0.1447 \n",
      "Epoch 42/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9633 - loss: 0.1190 \n",
      "Epoch 43/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9549 - loss: 0.1437 \n",
      "Epoch 44/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9592 - loss: 0.1200 \n",
      "Epoch 45/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9518 - loss: 0.1320 \n",
      "Epoch 46/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9540 - loss: 0.1323 \n",
      "Epoch 47/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9599 - loss: 0.1238 \n",
      "Epoch 48/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9589 - loss: 0.1311 \n",
      "Epoch 49/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9630 - loss: 0.1420 \n",
      "Epoch 50/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9624 - loss: 0.1102 \n",
      "Epoch 51/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9546 - loss: 0.1157 \n",
      "Epoch 52/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9634 - loss: 0.1218 \n",
      "Epoch 53/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9566 - loss: 0.1280 \n",
      "Epoch 54/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9652 - loss: 0.1101 \n",
      "Epoch 55/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9693 - loss: 0.1052 \n",
      "Epoch 56/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9660 - loss: 0.1102 \n",
      "Epoch 57/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9609 - loss: 0.1226 \n",
      "Epoch 58/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9774 - loss: 0.0921 \n",
      "Epoch 59/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9610 - loss: 0.1133 \n",
      "Epoch 60/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9630 - loss: 0.1193 \n",
      "Epoch 61/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9588 - loss: 0.1140 \n",
      "Epoch 62/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9665 - loss: 0.1135 \n",
      "Epoch 63/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9558 - loss: 0.1229 \n",
      "Epoch 64/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9626 - loss: 0.1065 \n",
      "Epoch 65/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9646 - loss: 0.1026 \n",
      "Epoch 66/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9756 - loss: 0.0999 \n",
      "Epoch 67/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9620 - loss: 0.1122 \n",
      "Epoch 68/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9810 - loss: 0.0970 \n",
      "Epoch 69/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9719 - loss: 0.0990 \n",
      "Epoch 70/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9464 - loss: 0.1231 \n",
      "Epoch 71/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9713 - loss: 0.0945 \n",
      "Epoch 72/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9728 - loss: 0.0914 \n",
      "Epoch 73/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9730 - loss: 0.1015 \n",
      "Epoch 74/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9745 - loss: 0.1048 \n",
      "Epoch 75/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9742 - loss: 0.1017 \n",
      "Epoch 76/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9706 - loss: 0.1139 \n",
      "Epoch 77/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9743 - loss: 0.0943 \n",
      "Epoch 78/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9787 - loss: 0.0941 \n",
      "Epoch 79/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9742 - loss: 0.1019 \n",
      "Epoch 80/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9792 - loss: 0.1004 \n",
      "Epoch 81/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9813 - loss: 0.0913 \n",
      "Epoch 82/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9769 - loss: 0.1089 \n",
      "Epoch 83/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9783 - loss: 0.1002 \n",
      "Epoch 84/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9864 - loss: 0.0829 \n",
      "Epoch 85/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9669 - loss: 0.1114 \n",
      "Epoch 86/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9686 - loss: 0.1098 \n",
      "Epoch 87/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9736 - loss: 0.0955 \n",
      "Epoch 88/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9762 - loss: 0.0932 \n",
      "Epoch 89/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9819 - loss: 0.0861 \n",
      "Epoch 90/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9809 - loss: 0.0907 \n",
      "Epoch 91/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9825 - loss: 0.0779 \n",
      "Epoch 92/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9810 - loss: 0.0928 \n",
      "Epoch 93/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9829 - loss: 0.1038 \n",
      "Epoch 94/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9739 - loss: 0.1067 \n",
      "Epoch 95/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9824 - loss: 0.0873 \n",
      "Epoch 96/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9814 - loss: 0.0962 \n",
      "Epoch 97/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9682 - loss: 0.1075 \n",
      "Epoch 98/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9722 - loss: 0.0919 \n",
      "Epoch 99/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9752 - loss: 0.0828 \n",
      "Epoch 100/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9721 - loss: 0.1135 \n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.history.History at 0x1bc8960bf80>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T16:00:57.589696Z",
     "start_time": "2024-04-02T16:00:45.987246Z"
    }
   },
   "id": "9fd3ba7d03c762c",
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calcoliamo e printiamo la loss e l'accuratezza sui dati di test:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "660103880fb9e7c4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9664 - loss: 0.0852  \n",
      "Loss sul test set: 0.0947\n",
      "Accuracy sul test set: 0.9591\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Loss sul test set: %.4f\" % loss)\n",
    "print(\"Accuracy sul test set: %.4f\" % acc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T16:02:20.986759Z",
     "start_time": "2024-04-02T16:02:20.718223Z"
    }
   },
   "id": "fee38bc9e14ee032",
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importiamo e grafichiamo la matrice di confusione per avere un'idea generale più precisa sulle misure di predizione fatte tramite il seguente modello"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bacb4b58e9a01cee"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "y_pred_int = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "cm = confusion_matrix(y_test, y_pred_int)\n",
    "labels = ['Benigno', 'Maligno']\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Valori predetti')\n",
    "plt.ylabel('Valori reali')\n",
    "plt.title('Matrice di confusione')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T16:03:11.904249Z",
     "start_time": "2024-04-02T16:03:11.418436Z"
    }
   },
   "id": "1f8253081f7bc32f",
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "source": [
    "Il nostro modello ha dunque:\n",
    "* sbagliato a categorizzare 4 tumori maligni come tumori benigni;\n",
    "* sbagliato a categorizzare 3 tumori benigni come tumori maligni;\n",
    "* correttamente categorizzato 105 tumori benigni su 108;\n",
    "* correttamente categorizzato 59 tumori maligni su 63."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db2315768ef7ae43"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Rete neurale densa profonda.\n",
    "Importiamo ora un modello di rete neurale densa profonda, cioè che avra più di uno strato denso nascosto, quindi il seguente modello conterrà:\n",
    "* 30 **nodi di input**, cioè pari al numero di features del dataframe, con funzione di attivazione **relu**;\n",
    "* 12 **nodi intermedi (nascosti)**, con funzione di attivazione **relu**;\n",
    "* 8 **nodi intermedi (nascosti)**, con funzione di attivazione **relu**;\n",
    "* 4 **nodi intermedi (nascosti)**, con funzione di attivazione **relu**;\n",
    "* 1 **nodo di output** essendo una categorizzazione binaria, con funzione di attivazione **sigmoidale**."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69d5354b3dd084a9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"sequential_9\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense_33 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m12\u001B[0m)             │            \u001B[38;5;34m60\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_34 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m)              │           \u001B[38;5;34m104\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_35 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m4\u001B[0m)              │            \u001B[38;5;34m36\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_36 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │             \u001B[38;5;34m5\u001B[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m205\u001B[0m (820.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205</span> (820.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m205\u001B[0m (820.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205</span> (820.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Dense(12, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model2.add(Dense(8, activation=\"relu\"))\n",
    "model2.add(Dense(4, activation=\"relu\"))\n",
    "model2.add(Dense(1, activation=\"sigmoid\"))\n",
    "model2.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model2.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T16:37:47.591887Z",
     "start_time": "2024-04-02T16:37:47.491883Z"
    }
   },
   "id": "fec02632410cd820",
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.3699 - loss: 0.6506\n",
      "Epoch 2/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.4149 - loss: 0.6240 \n",
      "Epoch 3/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.4841 - loss: 0.6245 \n",
      "Epoch 4/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6027 - loss: 0.5826 \n",
      "Epoch 5/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6458 - loss: 0.5897 \n",
      "Epoch 6/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7543 - loss: 0.5800 \n",
      "Epoch 7/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8026 - loss: 0.5654 \n",
      "Epoch 8/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8289 - loss: 0.5402 \n",
      "Epoch 9/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8581 - loss: 0.5202 \n",
      "Epoch 10/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9204 - loss: 0.5089 \n",
      "Epoch 11/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9282 - loss: 0.4987 \n",
      "Epoch 12/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9177 - loss: 0.4915 \n",
      "Epoch 13/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9070 - loss: 0.4728 \n",
      "Epoch 14/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9274 - loss: 0.4640 \n",
      "Epoch 15/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9458 - loss: 0.4508 \n",
      "Epoch 16/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9391 - loss: 0.4286 \n",
      "Epoch 17/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9288 - loss: 0.4431 \n",
      "Epoch 18/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9221 - loss: 0.4351 \n",
      "Epoch 19/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9314 - loss: 0.4235 \n",
      "Epoch 20/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9370 - loss: 0.4284 \n",
      "Epoch 21/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9530 - loss: 0.4001 \n",
      "Epoch 22/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9427 - loss: 0.3959 \n",
      "Epoch 23/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9431 - loss: 0.3807 \n",
      "Epoch 24/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9413 - loss: 0.3825 \n",
      "Epoch 25/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9555 - loss: 0.3620 \n",
      "Epoch 26/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9377 - loss: 0.3638 \n",
      "Epoch 27/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9401 - loss: 0.3564 \n",
      "Epoch 28/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9589 - loss: 0.3489 \n",
      "Epoch 29/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9401 - loss: 0.3505 \n",
      "Epoch 30/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9610 - loss: 0.3336 \n",
      "Epoch 31/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9358 - loss: 0.3443 \n",
      "Epoch 32/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9503 - loss: 0.3315 \n",
      "Epoch 33/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9520 - loss: 0.3275 \n",
      "Epoch 34/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9524 - loss: 0.3249 \n",
      "Epoch 35/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9551 - loss: 0.3130 \n",
      "Epoch 36/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9421 - loss: 0.3204 \n",
      "Epoch 37/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9536 - loss: 0.3170 \n",
      "Epoch 38/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9603 - loss: 0.2998 \n",
      "Epoch 39/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9499 - loss: 0.3033 \n",
      "Epoch 40/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9424 - loss: 0.2974 \n",
      "Epoch 41/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9443 - loss: 0.2983 \n",
      "Epoch 42/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9533 - loss: 0.2929 \n",
      "Epoch 43/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9585 - loss: 0.2743 \n",
      "Epoch 44/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9433 - loss: 0.2839 \n",
      "Epoch 45/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9464 - loss: 0.2897 \n",
      "Epoch 46/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9475 - loss: 0.2854 \n",
      "Epoch 47/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9569 - loss: 0.2737 \n",
      "Epoch 48/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9428 - loss: 0.2739 \n",
      "Epoch 49/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9581 - loss: 0.2624 \n",
      "Epoch 50/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9438 - loss: 0.2678 \n",
      "Epoch 51/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9586 - loss: 0.2534 \n",
      "Epoch 52/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9705 - loss: 0.2417 \n",
      "Epoch 53/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9540 - loss: 0.2617 \n",
      "Epoch 54/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9655 - loss: 0.2294 \n",
      "Epoch 55/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9650 - loss: 0.2375 \n",
      "Epoch 56/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9585 - loss: 0.2463 \n",
      "Epoch 57/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9563 - loss: 0.2352 \n",
      "Epoch 58/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9674 - loss: 0.2334 \n",
      "Epoch 59/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9591 - loss: 0.2358 \n",
      "Epoch 60/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9471 - loss: 0.2448 \n",
      "Epoch 61/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9514 - loss: 0.2276 \n",
      "Epoch 62/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9497 - loss: 0.2291 \n",
      "Epoch 63/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9470 - loss: 0.2465 \n",
      "Epoch 64/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9517 - loss: 0.2353 \n",
      "Epoch 65/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9530 - loss: 0.2269 \n",
      "Epoch 66/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9586 - loss: 0.2220 \n",
      "Epoch 67/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9472 - loss: 0.2307 \n",
      "Epoch 68/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9588 - loss: 0.2062 \n",
      "Epoch 69/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9585 - loss: 0.2156 \n",
      "Epoch 70/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9648 - loss: 0.1948 \n",
      "Epoch 71/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9613 - loss: 0.1987 \n",
      "Epoch 72/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9611 - loss: 0.2051 \n",
      "Epoch 73/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9625 - loss: 0.2012 \n",
      "Epoch 74/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9639 - loss: 0.1899 \n",
      "Epoch 75/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9554 - loss: 0.2021 \n",
      "Epoch 76/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9475 - loss: 0.2030 \n",
      "Epoch 77/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9445 - loss: 0.2096 \n",
      "Epoch 78/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9600 - loss: 0.1895 \n",
      "Epoch 79/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9567 - loss: 0.1911 \n",
      "Epoch 80/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9594 - loss: 0.1939 \n",
      "Epoch 81/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9419 - loss: 0.1979 \n",
      "Epoch 82/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9597 - loss: 0.1839 \n",
      "Epoch 83/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9589 - loss: 0.1806 \n",
      "Epoch 84/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9691 - loss: 0.1681 \n",
      "Epoch 85/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9558 - loss: 0.1842 \n",
      "Epoch 86/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9561 - loss: 0.1808 \n",
      "Epoch 87/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9583 - loss: 0.1745 \n",
      "Epoch 88/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9558 - loss: 0.1775 \n",
      "Epoch 89/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9616 - loss: 0.1810 \n",
      "Epoch 90/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9667 - loss: 0.1639 \n",
      "Epoch 91/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9813 - loss: 0.1555 \n",
      "Epoch 92/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9738 - loss: 0.1688 \n",
      "Epoch 93/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9750 - loss: 0.1587 \n",
      "Epoch 94/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9759 - loss: 0.1629 \n",
      "Epoch 95/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9640 - loss: 0.1679 \n",
      "Epoch 96/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9768 - loss: 0.1567 \n",
      "Epoch 97/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9730 - loss: 0.1525 \n",
      "Epoch 98/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9653 - loss: 0.1715 \n",
      "Epoch 99/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9757 - loss: 0.1597 \n",
      "Epoch 100/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9689 - loss: 0.1673 \n",
      "Epoch 101/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9699 - loss: 0.1639 \n",
      "Epoch 102/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9798 - loss: 0.1509 \n",
      "Epoch 103/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9779 - loss: 0.1493 \n",
      "Epoch 104/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9746 - loss: 0.1554 \n",
      "Epoch 105/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9772 - loss: 0.1455 \n",
      "Epoch 106/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9624 - loss: 0.1649 \n",
      "Epoch 107/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9812 - loss: 0.1429 \n",
      "Epoch 108/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9729 - loss: 0.1578 \n",
      "Epoch 109/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9764 - loss: 0.1472 \n",
      "Epoch 110/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9786 - loss: 0.1477 \n",
      "Epoch 111/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9759 - loss: 0.1377 \n",
      "Epoch 112/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9746 - loss: 0.1459 \n",
      "Epoch 113/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9798 - loss: 0.1377 \n",
      "Epoch 114/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9627 - loss: 0.1589 \n",
      "Epoch 115/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9723 - loss: 0.1392 \n",
      "Epoch 116/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9738 - loss: 0.1388 \n",
      "Epoch 117/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9709 - loss: 0.1410 \n",
      "Epoch 118/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9843 - loss: 0.1250 \n",
      "Epoch 119/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9811 - loss: 0.1297 \n",
      "Epoch 120/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9729 - loss: 0.1433 \n",
      "Epoch 121/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9742 - loss: 0.1363 \n",
      "Epoch 122/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9707 - loss: 0.1433 \n",
      "Epoch 123/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9710 - loss: 0.1373 \n",
      "Epoch 124/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9785 - loss: 0.1306 \n",
      "Epoch 125/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9811 - loss: 0.1245 \n",
      "Epoch 126/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9792 - loss: 0.1220 \n",
      "Epoch 127/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9726 - loss: 0.1338 \n",
      "Epoch 128/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9800 - loss: 0.1259 \n",
      "Epoch 129/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9711 - loss: 0.1422 \n",
      "Epoch 130/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9758 - loss: 0.1279 \n",
      "Epoch 131/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9883 - loss: 0.1148 \n",
      "Epoch 132/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9845 - loss: 0.1242 \n",
      "Epoch 133/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9836 - loss: 0.1196 \n",
      "Epoch 134/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9717 - loss: 0.1354 \n",
      "Epoch 135/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9680 - loss: 0.1315 \n",
      "Epoch 136/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9827 - loss: 0.1173 \n",
      "Epoch 137/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9844 - loss: 0.1161 \n",
      "Epoch 138/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9767 - loss: 0.1382 \n",
      "Epoch 139/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9830 - loss: 0.1218 \n",
      "Epoch 140/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9797 - loss: 0.1197 \n",
      "Epoch 141/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9794 - loss: 0.1211 \n",
      "Epoch 142/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9812 - loss: 0.1187 \n",
      "Epoch 143/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9694 - loss: 0.1367 \n",
      "Epoch 144/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9769 - loss: 0.1236 \n",
      "Epoch 145/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9804 - loss: 0.1211 \n",
      "Epoch 146/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9841 - loss: 0.1127 \n",
      "Epoch 147/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9842 - loss: 0.1113 \n",
      "Epoch 148/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9880 - loss: 0.1111 \n",
      "Epoch 149/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9909 - loss: 0.1050 \n",
      "Epoch 150/150\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9780 - loss: 0.1268 \n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.history.History at 0x1bc87574b90>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train, epochs=150)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T16:12:26.186799Z",
     "start_time": "2024-04-02T16:12:14.289788Z"
    }
   },
   "id": "eaa65f9d44001699",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9886 - loss: 0.1018 \n",
      "Loss sul test set: 0.1127\n",
      "Accuracy sul test set: 0.9766\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model2.evaluate(X_test, y_test)\n",
    "print(\"Loss sul test set: %.4f\" % loss)\n",
    "print(\"Accuracy sul test set: %.4f\" % acc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T16:12:45.478993Z",
     "start_time": "2024-04-02T16:12:45.316258Z"
    }
   },
   "id": "b9080bab2b4257bb",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred=model2.predict(X_test)\n",
    "y_pred_int = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "cm = confusion_matrix(y_test, y_pred_int)\n",
    "labels = ['Benigno', 'Maligno']\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Valori predetti')\n",
    "plt.ylabel('Valori reali')\n",
    "plt.title('Matrice di confusione')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T16:12:47.195632Z",
     "start_time": "2024-04-02T16:12:46.571147Z"
    }
   },
   "id": "a1eb6acc9463fde1",
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "source": [
    "Il nostro modello ha dunque:\n",
    "* sbagliato a categorizzare 2 tumori maligni come tumori benigni;\n",
    "* sbagliato a categorizzare 2 tumori benigni come tumori maligni;\n",
    "* correttamente categorizzato 106 tumori benigni su 108;\n",
    "* correttamente categorizzato 61 tumori maligni su 63.\n",
    "\n",
    "Solo aggiungendo qualche strato nascosto in più, il nostro modello di rete neurale artificiale è migliorato notevolmente"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df120af87c3b06ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CATEGORIZZAZIONE DELLA SPECIE DEI FIORI (DATASET IRIS) TRAMITE RETE NEURALE DENSA\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a91678d6ed6e1c65"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Andiamo direttamente ad importare la rete neurale densa profonda, ma con qualche dettaglio che andrà cambiato, trattandosi di una categorizzazione a tre classi.\n",
    "\n",
    "Importiamo dunque il dataset e dividiamo le features e i target nei set di addestramento e test:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "117da5cf058b9e6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset=load_iris()     \n",
    "X=dataset.data          \n",
    "y=dataset.target        \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T16:27:52.940665Z",
     "start_time": "2024-04-02T16:27:52.931371Z"
    }
   },
   "id": "5520f19056e09309",
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creiamo il nostro modello di rete neurale densa profonda, sta volta per le funzioni di attivazione degli strati nascosti utilizziamo la **LeakyReLU**, questo cambiamento non è dato dal fatto che ci siano 3 classi, andava ugualmente bene anche la funzione **ReLU**. Quindi la nostra rete neurale sarà composta da:\n",
    "* 4 **nodi di input**, cioè il numero di features del nostro dataframe, con funzione di attivazione **LeakyReLU**;\n",
    "* 20 **nodi di intermedi (nascosti)**, con funzione di attivazione **LeakyReLU**;\n",
    "* 16 **nodi di intermedi (nascosti)**, con funzione di attivazione **LeakyReLU**;\n",
    "* 8 **nodi di intermedi (nascosti)**, con funzione di attivazione **LeakyReLU**;\n",
    "* 3 **nodi di output**, con funzione di attivazione **Softmax**.\n",
    "\n",
    "Ciò che è cambiato è che ora il numero di nodi di output è uguale al numero delle classi non trattandosi più di una categorizzazione binaria, la funzione di attivazione dello strato finale è la **softmax**, che restituisce la probabilità normalizzata per ogni classe. Inoltre cambia la funzione di loss e l'ottimizzazione."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c92c923333aa632c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\simon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"sequential_8\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense_29 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m20\u001B[0m)             │           \u001B[38;5;34m100\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_12 (\u001B[38;5;33mLeakyReLU\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m20\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_30 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m)             │           \u001B[38;5;34m336\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_13 (\u001B[38;5;33mLeakyReLU\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_31 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m)              │           \u001B[38;5;34m136\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_14 (\u001B[38;5;33mLeakyReLU\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m)              │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_32 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m)              │            \u001B[38;5;34m27\u001B[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">336</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m599\u001B[0m (2.34 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">599</span> (2.34 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m599\u001B[0m (2.34 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">599</span> (2.34 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(20, input_dim=X_train.shape[1]))\n",
    "model3.add(LeakyReLU(alpha=0.1))\n",
    "model3.add(Dense(16))\n",
    "model3.add(LeakyReLU(alpha=0.1))\n",
    "model3.add(Dense(8))\n",
    "model3.add(LeakyReLU(alpha=0.1))\n",
    "model3.add(Dense(3, activation=\"softmax\"))\n",
    "model3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T16:36:45.819927Z",
     "start_time": "2024-04-02T16:36:45.701690Z"
    }
   },
   "id": "a46a80853b172814",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.3896 - loss: 0.8994\n",
      "Epoch 2/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6766 - loss: 0.8211 \n",
      "Epoch 3/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6808 - loss: 0.7688 \n",
      "Epoch 4/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6871 - loss: 0.7268 \n",
      "Epoch 5/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.7443 - loss: 0.6747 \n",
      "Epoch 6/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6756 - loss: 0.6817 \n",
      "Epoch 7/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6516 - loss: 0.6647  \n",
      "Epoch 8/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6548 - loss: 0.6414 \n",
      "Epoch 9/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6725 - loss: 0.6146 \n",
      "Epoch 10/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6787 - loss: 0.5951 \n",
      "Epoch 11/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6412 - loss: 0.5961 \n",
      "Epoch 12/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6641 - loss: 0.5743 \n",
      "Epoch 13/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6969 - loss: 0.5422 \n",
      "Epoch 14/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6781 - loss: 0.5226 \n",
      "Epoch 15/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.7202 - loss: 0.4904 \n",
      "Epoch 16/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6930 - loss: 0.5024 \n",
      "Epoch 17/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8103 - loss: 0.4657 \n",
      "Epoch 18/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8747 - loss: 0.4367 \n",
      "Epoch 19/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8936 - loss: 0.4191 \n",
      "Epoch 20/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8838 - loss: 0.4145 \n",
      "Epoch 21/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8848 - loss: 0.3876 \n",
      "Epoch 22/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9126 - loss: 0.3649 \n",
      "Epoch 23/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9064 - loss: 0.3769 \n",
      "Epoch 24/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9193 - loss: 0.3516 \n",
      "Epoch 25/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9204 - loss: 0.3415 \n",
      "Epoch 26/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9433 - loss: 0.3358 \n",
      "Epoch 27/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9266 - loss: 0.3215 \n",
      "Epoch 28/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9496 - loss: 0.3076 \n",
      "Epoch 29/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9417 - loss: 0.2866 \n",
      "Epoch 30/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9555 - loss: 0.2898 \n",
      "Epoch 31/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9586 - loss: 0.2963 \n",
      "Epoch 32/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9618 - loss: 0.2778 \n",
      "Epoch 33/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9521 - loss: 0.2644 \n",
      "Epoch 34/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9400 - loss: 0.2715 \n",
      "Epoch 35/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9820 - loss: 0.2507 \n",
      "Epoch 36/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9612 - loss: 0.2634 \n",
      "Epoch 37/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9856 - loss: 0.2421 \n",
      "Epoch 38/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9795 - loss: 0.2302 \n",
      "Epoch 39/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9732 - loss: 0.2187 \n",
      "Epoch 40/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9732 - loss: 0.2350 \n",
      "Epoch 41/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9726 - loss: 0.2141 \n",
      "Epoch 42/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9793 - loss: 0.2262 \n",
      "Epoch 43/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9799 - loss: 0.2084 \n",
      "Epoch 44/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9793 - loss: 0.1975 \n",
      "Epoch 45/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9699 - loss: 0.2099 \n",
      "Epoch 46/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9705 - loss: 0.1943 \n",
      "Epoch 47/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9493 - loss: 0.1847 \n",
      "Epoch 48/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9789 - loss: 0.1769 \n",
      "Epoch 49/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9824 - loss: 0.1714 \n",
      "Epoch 50/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9762 - loss: 0.1669 \n",
      "Epoch 51/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9699 - loss: 0.1764 \n",
      "Epoch 52/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9699 - loss: 0.1690 \n",
      "Epoch 53/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9824 - loss: 0.1657 \n",
      "Epoch 54/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9929 - loss: 0.1513 \n",
      "Epoch 55/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9856 - loss: 0.1470 \n",
      "Epoch 56/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9824 - loss: 0.1314 \n",
      "Epoch 57/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9799 - loss: 0.1142 \n",
      "Epoch 58/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9793 - loss: 0.1127 \n",
      "Epoch 59/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9699 - loss: 0.1295 \n",
      "Epoch 60/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.1229 \n",
      "Epoch 61/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9726 - loss: 0.1132 \n",
      "Epoch 62/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9799 - loss: 0.1047 \n",
      "Epoch 63/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9887 - loss: 0.1122 \n",
      "Epoch 64/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9850 - loss: 0.1107 \n",
      "Epoch 65/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9793 - loss: 0.0952 \n",
      "Epoch 66/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9643 - loss: 0.1220 \n",
      "Epoch 67/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9793 - loss: 0.1020 \n",
      "Epoch 68/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9908 - loss: 0.0897 \n",
      "Epoch 69/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9762 - loss: 0.0950 \n",
      "Epoch 70/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9793 - loss: 0.0855 \n",
      "Epoch 71/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9887 - loss: 0.0875 \n",
      "Epoch 72/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9856 - loss: 0.0851 \n",
      "Epoch 73/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9814 - loss: 0.1004 \n",
      "Epoch 74/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9887 - loss: 0.0759 \n",
      "Epoch 75/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9856 - loss: 0.0828 \n",
      "Epoch 76/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9793 - loss: 0.0868 \n",
      "Epoch 77/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9699 - loss: 0.0896 \n",
      "Epoch 78/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9762 - loss: 0.0858 \n",
      "Epoch 79/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9699 - loss: 0.0945 \n",
      "Epoch 80/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9814 - loss: 0.0902 \n",
      "Epoch 81/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9876 - loss: 0.0785 \n",
      "Epoch 82/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9762 - loss: 0.0825 \n",
      "Epoch 83/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9887 - loss: 0.0702 \n",
      "Epoch 84/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9762 - loss: 0.0830 \n",
      "Epoch 85/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9793 - loss: 0.0720 \n",
      "Epoch 86/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9876 - loss: 0.0756 \n",
      "Epoch 87/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9762 - loss: 0.0766 \n",
      "Epoch 88/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9824 - loss: 0.0716 \n",
      "Epoch 89/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9876 - loss: 0.0694 \n",
      "Epoch 90/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9908 - loss: 0.0717 \n",
      "Epoch 91/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9699 - loss: 0.0862 \n",
      "Epoch 92/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9908 - loss: 0.0618 \n",
      "Epoch 93/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.0924 \n",
      "Epoch 94/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9793 - loss: 0.0767 \n",
      "Epoch 95/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9824 - loss: 0.0645 \n",
      "Epoch 96/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9699 - loss: 0.0830 \n",
      "Epoch 97/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9793 - loss: 0.0698 \n",
      "Epoch 98/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9699 - loss: 0.0775 \n",
      "Epoch 99/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9793 - loss: 0.0685 \n",
      "Epoch 100/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9856 - loss: 0.0616 \n",
      "Epoch 101/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9943 - loss: 0.0733 \n",
      "Epoch 102/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9699 - loss: 0.0678 \n",
      "Epoch 103/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9793 - loss: 0.0660 \n",
      "Epoch 104/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9824 - loss: 0.0627 \n",
      "Epoch 105/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9762 - loss: 0.0687 \n",
      "Epoch 106/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9814 - loss: 0.0704 \n",
      "Epoch 107/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9814 - loss: 0.0672 \n",
      "Epoch 108/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9824 - loss: 0.0631 \n",
      "Epoch 109/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9856 - loss: 0.0488 \n",
      "Epoch 110/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9793 - loss: 0.0647 \n",
      "Epoch 111/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9793 - loss: 0.0721 \n",
      "Epoch 112/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9699 - loss: 0.0715 \n",
      "Epoch 113/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9824 - loss: 0.0601 \n",
      "Epoch 114/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9793 - loss: 0.0607 \n",
      "Epoch 115/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9762 - loss: 0.0630 \n",
      "Epoch 116/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9856 - loss: 0.0565 \n",
      "Epoch 117/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.0639 \n",
      "Epoch 118/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9912 - loss: 0.0577 \n",
      "Epoch 119/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9876 - loss: 0.0590 \n",
      "Epoch 120/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9824 - loss: 0.0593 \n",
      "Epoch 121/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9856 - loss: 0.0521 \n",
      "Epoch 122/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.0607 \n",
      "Epoch 123/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9887 - loss: 0.0475 \n",
      "Epoch 124/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9887 - loss: 0.0466 \n",
      "Epoch 125/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9762 - loss: 0.0587 \n",
      "Epoch 126/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9912 - loss: 0.0506 \n",
      "Epoch 127/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9908 - loss: 0.0468 \n",
      "Epoch 128/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9943 - loss: 0.0407 \n",
      "Epoch 129/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9856 - loss: 0.0506 \n",
      "Epoch 130/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9762 - loss: 0.0564 \n",
      "Epoch 131/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9699 - loss: 0.0584 \n",
      "Epoch 132/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9912 - loss: 0.0509 \n",
      "Epoch 133/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9943 - loss: 0.0572 \n",
      "Epoch 134/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9856 - loss: 0.0430 \n",
      "Epoch 135/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.0554 \n",
      "Epoch 136/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9943 - loss: 0.0548 \n",
      "Epoch 137/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9912 - loss: 0.0523 \n",
      "Epoch 138/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9762 - loss: 0.0558 \n",
      "Epoch 139/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9793 - loss: 0.0587 \n",
      "Epoch 140/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9912 - loss: 0.0486 \n",
      "Epoch 141/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.0475 \n",
      "Epoch 142/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9856 - loss: 0.0499 \n",
      "Epoch 143/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9908 - loss: 0.0413 \n",
      "Epoch 144/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9762 - loss: 0.0464 \n",
      "Epoch 145/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.0510 \n",
      "Epoch 146/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9912 - loss: 0.0545 \n",
      "Epoch 147/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9856 - loss: 0.0483 \n",
      "Epoch 148/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9824 - loss: 0.0472 \n",
      "Epoch 149/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9943 - loss: 0.0395 \n",
      "Epoch 150/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.0505 \n",
      "Epoch 151/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9943 - loss: 0.0403 \n",
      "Epoch 152/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.0506 \n",
      "Epoch 153/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9908 - loss: 0.0380 \n",
      "Epoch 154/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.0543 \n",
      "Epoch 155/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9943 - loss: 0.0410 \n",
      "Epoch 156/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.0445 \n",
      "Epoch 157/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9943 - loss: 0.0443 \n",
      "Epoch 158/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9908 - loss: 0.0350 \n",
      "Epoch 159/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9964 - loss: 0.0353 \n",
      "Epoch 160/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9943 - loss: 0.0358 \n",
      "Epoch 161/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9943 - loss: 0.0436 \n",
      "Epoch 162/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9964 - loss: 0.0417 \n",
      "Epoch 163/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9699 - loss: 0.0581 \n",
      "Epoch 164/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.0491 \n",
      "Epoch 165/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.0477 \n",
      "Epoch 166/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9887 - loss: 0.0330 \n",
      "Epoch 167/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.0461 \n",
      "Epoch 168/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9964 - loss: 0.0382 \n",
      "Epoch 169/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.0452 \n",
      "Epoch 170/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9943 - loss: 0.0313 \n",
      "Epoch 171/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.0458 \n",
      "Epoch 172/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.0462 \n",
      "Epoch 173/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9912 - loss: 0.0366 \n",
      "Epoch 174/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.0405 \n",
      "Epoch 175/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9850 - loss: 0.0444 \n",
      "Epoch 176/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9943 - loss: 0.0382 \n",
      "Epoch 177/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9850 - loss: 0.0522 \n",
      "Epoch 178/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9762 - loss: 0.0426 \n",
      "Epoch 179/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.0424 \n",
      "Epoch 180/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9943 - loss: 0.0371 \n",
      "Epoch 181/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9912 - loss: 0.0346 \n",
      "Epoch 182/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.0438 \n",
      "Epoch 183/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9943 - loss: 0.0342 \n",
      "Epoch 184/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9964 - loss: 0.0296 \n",
      "Epoch 185/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9943 - loss: 0.0274 \n",
      "Epoch 186/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9964 - loss: 0.0414 \n",
      "Epoch 187/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9943 - loss: 0.0334 \n",
      "Epoch 188/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.0434 \n",
      "Epoch 189/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9964 - loss: 0.0298 \n",
      "Epoch 190/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9912 - loss: 0.0383 \n",
      "Epoch 191/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9912 - loss: 0.0373 \n",
      "Epoch 192/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.0422 \n",
      "Epoch 193/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9964 - loss: 0.0304 \n",
      "Epoch 194/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9964 - loss: 0.0322 \n",
      "Epoch 195/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.0372 \n",
      "Epoch 196/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9850 - loss: 0.0449 \n",
      "Epoch 197/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9912 - loss: 0.0338 \n",
      "Epoch 198/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9912 - loss: 0.0324 \n",
      "Epoch 199/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9943 - loss: 0.0323 \n",
      "Epoch 200/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9850 - loss: 0.0418 \n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.history.History at 0x1bcf21b5a60>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train, y_train, epochs=200)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T16:37:01.499292Z",
     "start_time": "2024-04-02T16:36:47.454398Z"
    }
   },
   "id": "c827428d01081ca",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9720 - loss: 0.1133  \n",
      "Loss sul test set: 0.0862\n",
      "Accuracy sul test set: 0.9737\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model3.evaluate(X_test, y_test)\n",
    "print(\"Loss sul test set: %.4f\" % loss)\n",
    "print(\"Accuracy sul test set: %.4f\" % acc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T16:37:06.001860Z",
     "start_time": "2024-04-02T16:37:05.708938Z"
    }
   },
   "id": "a6b04aea2e4cedb0",
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 63ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred=model3.predict(X_test)\n",
    "y_pred_int = np.argmax(y_pred, axis=1)\n",
    "cm = confusion_matrix(y_test, y_pred_int)\n",
    "labels = ['Setosa', 'Versicolor', 'Virginica']\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Valori predetti')\n",
    "plt.ylabel('Valori reali')\n",
    "plt.title('Matrice di confusione')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T16:37:11.295339Z",
     "start_time": "2024-04-02T16:37:10.424327Z"
    }
   },
   "id": "edaf3c433dad21ce",
   "execution_count": 70
  },
  {
   "cell_type": "markdown",
   "source": [
    "Il nostro modello ha dunque:\n",
    "* sbagliato a categorizzare una Versicolor come una Virginica;\n",
    "* Correttamente categorizzato il resto dei fiori."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d92d7bf8338b978a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d0fa98763f3174cb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
